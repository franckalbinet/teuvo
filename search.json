[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Teuvo",
    "section": "",
    "text": "Developed through the innovative “SolveIt” tool and methodology currently featured at Answer.ai, this Python package embodies a transformative approach to problem-solving. Rather than treating AI as a mysterious black box that simply produces answers, it leverages AI as an illuminating tool that deepens our understanding of problems and guides us toward solutions.\nAt its core, the package draws inspiration from George Pólya’s seminal “How to Solve It” framework. What makes this implementation unique is its radical commitment to transparency and literate programming - the entire development process is meticulously documented in this “How was it created?” notebook, serving as both a comprehensive guide and a testament to the step-by-step problem-solving methodology.\nThe package’s source code emerges naturally from this foundational notebook, carefully refactoring the core functionality that was thoughtfully developed through deliberate, incremental steps. This approach ensures that every component is not only well-documented but also deeply understood.",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#design-philosophy",
    "href": "index.html#design-philosophy",
    "title": "Teuvo",
    "section": "",
    "text": "Developed through the innovative “SolveIt” tool and methodology currently featured at Answer.ai, this Python package embodies a transformative approach to problem-solving. Rather than treating AI as a mysterious black box that simply produces answers, it leverages AI as an illuminating tool that deepens our understanding of problems and guides us toward solutions.\nAt its core, the package draws inspiration from George Pólya’s seminal “How to Solve It” framework. What makes this implementation unique is its radical commitment to transparency and literate programming - the entire development process is meticulously documented in this “How was it created?” notebook, serving as both a comprehensive guide and a testament to the step-by-step problem-solving methodology.\nThe package’s source code emerges naturally from this foundational notebook, carefully refactoring the core functionality that was thoughtfully developed through deliberate, incremental steps. This approach ensures that every component is not only well-documented but also deeply understood.",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Teuvo",
    "section": "Features",
    "text": "Features\n\nMultiple initialization methods:\n\nRandom initialization\nPCA-based initialization (for faster convergence)\n\nFlexible training options:\n\nCustomizable learning rate schedules\nAdjustable neighborhood functions\nQuantization and Topographic Errors monitoring plots during training:\n\n\n\n\nComprehensive quality metrics:\n\nQuantization Error\nTopographic Error\n\nRich visualization tools:\n\nU-Matrix visualization\nHit histograms and Component planes (coming soon)",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Teuvo",
    "section": "Installation",
    "text": "Installation\npip install teuvo",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "Teuvo",
    "section": "Quick Start",
    "text": "Quick Start\n\nfrom teuvo.core import SOM\nimport numpy as np\nfrom sklearn.datasets import load_digits\n\n# Load and normalize MNIST data\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Create and train SOM\nsom = SOM(grid_sz=(20,20), input_dim=64, init='pca')\nsom.fit(X_norm, n_epochs=20, verbose=True)\n\n# Visualize results\nsom.plot_umatrix(figsize=(4,4))\n\n\n    \n        Training Progress\n        \n\n\n\nEpoch\nQE\nTE\n\n\n1\n2.0001\n2.0590\n\n\n2\n1.9462\n4.7301\n\n\n3\n1.8539\n0.6121\n\n\n4\n1.8458\n1.5582\n\n\n5\n1.7964\n1.8364\n\n\n6\n1.7228\n0.7791\n\n\n7\n1.6385\n0.4452\n\n\n8\n1.5939\n0.3339\n\n\n9\n1.5624\n0.3339\n\n\n10\n1.4959\n0.5565\n\n\n11\n1.4390\n0.6121\n\n\n12\n1.3935\n0.6678\n\n\n13\n1.3539\n0.6678\n\n\n14\n1.3116\n0.8904\n\n\n15\n1.2758\n1.0017\n\n\n16\n1.2444\n0.7234\n\n\n17\n1.2162\n0.7234\n\n\n18\n1.1915\n0.7234\n\n\n19\n1.1701\n0.8347\n\n\n20\n1.1523\n0.6678",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#detailed-example-mnist-digit-classification",
    "href": "index.html#detailed-example-mnist-digit-classification",
    "title": "Teuvo",
    "section": "Detailed Example: MNIST Digit Classification",
    "text": "Detailed Example: MNIST Digit Classification\n\nfrom teuvo.core import SOM, Scheduler\nimport numpy as np\nfrom sklearn.datasets import load_digits\nimport matplotlib.pyplot as plt\n\n# Load and preprocess data\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Initialize SOM\nsom = SOM(\n    grid_sz=(20,20),\n    input_dim=64,\n    init='pca'  # Use PCA initialization\n)\n\n# Create custom schedulers\nlr_scheduler = Scheduler(start_val=1.0, end_val=0.01, \n                         step_size=200, n_samples=len(X), n_epochs=20)\nsigma_scheduler = Scheduler(start_val=10.0, end_val=1.0, \n                            step_size=200, n_samples=len(X), n_epochs=20)\n\n# Train\nweights, qe_errors, te_errors = som.fit(\n    X_norm,\n    n_epochs=15,\n    lr_scheduler=lr_scheduler,\n    sigma_scheduler=sigma_scheduler\n)\n\n\n    \n        Training Progress\n        \n\n\n\nEpoch\nQE\nTE\n\n\n1\n1.9399\n1.3912\n\n\n2\n2.0015\n1.6694\n\n\n3\n1.9254\n2.7824\n\n\n4\n1.7919\n0.6121\n\n\n5\n1.7639\n1.1686\n\n\n6\n1.7188\n0.7791\n\n\n7\n1.6138\n0.6121\n\n\n8\n1.5829\n0.4452\n\n\n9\n1.5376\n0.2782\n\n\n10\n1.4790\n0.5008\n\n\n11\n1.4333\n0.3339\n\n\n12\n1.3924\n0.3895\n\n\n13\n1.3472\n1.0017\n\n\n14\n1.3150\n0.2782\n\n\n15\n1.2801\n0.3895\n\n\n\n\n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsom.plot_umatrix(figsize=(4,4))",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Teuvo",
    "section": "Contributing",
    "text": "Contributing\nWe welcome contributions! Please see our contributing guidelines for details.",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Teuvo",
    "section": "References",
    "text": "References\n\nKohonen, T. (1982). Self-organized formation of topologically correct feature maps\nKohonen, T. (2013). Essentials of the self-organizing map\nPolya, G. (1945). How to Solve It",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Teuvo",
    "section": "License",
    "text": "License\nApache 2.0",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Teuvo",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nNamed in honor of Teuvo Kohonen, who introduced the Self-Organizing Map algorithm.",
    "crumbs": [
      "Teuvo"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nSOM\n\n SOM (grid_sz:tuple, input_dim:int, init:str='random', dist_fn=&lt;function\n      &lt;lambda&gt;&gt;)\n\nInitialize a Self-Organizing Map with given grid size and input dimension\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngrid_sz\ntuple\n\ngrid size\n\n\ninput_dim\nint\n\ninput dimension\n\n\ninit\nstr\nrandom\ninitialization method\n\n\ndist_fn\nfunction\n\ndistance function\n\n\nReturns\nNone\n\ninitialize the SOM\n\n\n\n\n\nExported source\ndist_fn = lambda x, ws: np.linalg.norm(ws-x, axis=-1)\n\n\n\n\nExported source\nclass SOM:\n    def __init__(self, \n                 grid_sz:tuple, # grid size\n                 input_dim:int, # input dimension\n                 init:str='random', # initialization method\n                #  dist_fn=np.linalg.norm # distance function\n                 dist_fn=dist_fn # distance function\n                 )-&gt;None: # initialize the SOM\n        \"Initialize a Self-Organizing Map with given grid size and input dimension\"\n        store_attr()\n        self.weights = None  # Will be initialized when fitting\n\n\n\nsource\n\n\nexp_sched\n\n exp_sched (start_val, end_val, i, n_steps)\n\n\n\nExported source\n@patch\ndef _initialize_weights_pca(self:SOM, X:np.ndarray)-&gt;np.ndarray:\n    \"Initialize weights using PCA of the input data\"\n    pca = PCA(n_components=2)\n    pca.fit(X)\n    \n    # Create grid coordinates and scale by eigenvalues\n    n = self.grid_sz[0]\n    alpha = np.linspace(-1, 1, n) * np.sqrt(pca.explained_variance_[0])\n    beta = np.linspace(-1, 1, n) * np.sqrt(pca.explained_variance_[1])\n    \n    # Create the grid\n    alpha_grid, beta_grid = np.meshgrid(alpha, beta)\n    \n    # Initialize weights as linear combination of first two PCs\n    return (alpha_grid[..., np.newaxis] * pca.components_[0] + \n            beta_grid[..., np.newaxis] * pca.components_[1])\n\n\n\n\nExported source\n@patch\ndef _initialize_weights(self:SOM, \n                        X:np.ndarray=None, # data matrix\n                        method:str='random' # initialization method\n                        )-&gt;np.ndarray: # weights matrix\n    \"Initialize weights using either random or PCA initialization\"\n    if method == 'random':\n        return np.random.randn(*self.grid_sz, self.input_dim)\n    elif method == 'pca':\n        if X is None: \n            raise ValueError(\"Data matrix X required for PCA initialization\")\n        return self._initialize_weights_pca(X)\n\n\n\n\nExported source\n@patch\ndef _find_bmu(self:SOM, \n              x:np.ndarray, # input vector\n              )-&gt;tuple: # coordinates of the best matching unit\n    \"Find coordinates of Best Matching Unit for input x\"\n    distances = self.dist_fn(x, self.weights)\n    return np.unravel_index(np.argmin(distances), self.grid_sz)\n\n\n\n\nExported source\n@patch\ndef _grid_distances(self:SOM, \n                    bmu_pos:tuple # coordinates of the best matching unit\n                    )-&gt;np.ndarray: # grid distances\n    \"Calculate grid distances from BMU position\"\n    rows_idx, cols_idx = np.ogrid[0:self.grid_sz[0], 0:self.grid_sz[1]]\n    return (bmu_pos[0] - rows_idx)**2 + (bmu_pos[1] - cols_idx)**2\n\n\n\n\nExported source\n@patch\ndef _neighborhood_function(self:SOM, \n                           grid_dist:np.ndarray, # grid distances\n                           sigma:float # neighborhood radius\n                           )-&gt;np.ndarray: # neighborhood function values\n    \"Calculate neighborhood function values\"\n    return np.exp(-grid_dist/(2*sigma**2))\n\n\n\n\nExported source\n@patch\ndef _update_weights(self:SOM, \n                    x:np.ndarray, # input vector\n                    learning_rate:float, # learning rate\n                    sigma:float # neighborhood radius\n                    )-&gt;None: # update weights\n    \"Update weights for a single input vector\"\n    bmu_pos = self._find_bmu(x)\n    grid_dist = self._grid_distances(bmu_pos)\n    neighborhood = self._neighborhood_function(grid_dist, sigma)\n    self.weights += learning_rate * neighborhood[..., np.newaxis] * (x - self.weights)\n\n\n\n\nExported source\ndef exp_sched(start_val, end_val, i, n_steps):\n    decay = -np.log(end_val/start_val)/n_steps\n    return start_val * np.exp(-decay * i)\n\n\n\nsource\n\n\nScheduler\n\n Scheduler (start_val, end_val, step_size, n_samples, n_epochs,\n            decay_fn=&lt;function exp_sched&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\nclass Scheduler:\n    def __init__(self, start_val, end_val, step_size, \n                 n_samples, n_epochs, decay_fn=exp_sched):\n        store_attr()\n        self.current_step = 0\n        self.current_value = start_val\n        self.total_steps = (n_samples * n_epochs) // step_size\n    \n    def step(self, total_samples):\n        if total_samples % self.step_size == 0:\n            self.current_value = self.decay_fn(\n                self.start_val, self.end_val, \n                self.current_step, self.total_steps\n            )\n            self.current_step += 1\n        return self.current_value\n\n\n\nsource\n\n\nformat_metrics_html\n\n format_metrics_html (epochs_data:list)\n\n\n\n\n\nType\nDetails\n\n\n\n\nepochs_data\nlist\nlist of tuples: [(epoch, qe, te), …]\n\n\n\n\n\nExported source\ndef format_metrics_html(\n    epochs_data:list, # list of tuples: [(epoch, qe, te), ...]\n    ):\n    # Format the metrics as an HTML table\n    # epochs_data should be a list of tuples: [(epoch, qe, te), ...]\n    rows = ''.join([\n        f\"\"\"\n            &lt;tr&gt;\n                &lt;td style=\"padding: 3px\"&gt;{epoch+1:3d}&lt;/td&gt;\n                &lt;td style=\"padding: 3px\"&gt;{qe:8.4f}&lt;/td&gt;\n                &lt;td style=\"padding: 3px\"&gt;{te:8.4f}&lt;/td&gt;\n            &lt;/tr&gt;\n        \"\"\" for epoch, qe, te in epochs_data\n    ])\n    \n    return f\"\"\"\n    &lt;div style=\"font-family: monospace; margin: 10px\"&gt;\n        &lt;h4&gt;Training Progress&lt;/h4&gt;\n        &lt;table style=\"border-collapse: collapse\"&gt;\n            &lt;tr style=\"border-bottom: 2px solid #ddd\"&gt;\n                &lt;th style=\"font-weight: bold; padding: 5px; text-align: left\"&gt;Epoch&lt;/th&gt;\n                &lt;th style=\"font-weight: bold; padding: 5px; text-align: right\"&gt;QE&lt;/th&gt;\n                &lt;th style=\"font-weight: bold; padding: 5px; text-align: right\"&gt;TE&lt;/th&gt;\n            &lt;/tr&gt;\n            {rows}\n        &lt;/table&gt;\n    &lt;/div&gt;\n    \"\"\"\n\n\n\nsource\n\n\nsetup_error_plots\n\n setup_error_plots (**kwargs)\n\nSetup error plots\n\n\nExported source\ndef setup_error_plots(**kwargs):\n    \"Setup error plots\"\n    kwargs.get('figsize')\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=kwargs.get('figsize', (8, 3)), dpi=kwargs.get('dpi', 100))\n    ax1.set_title('Quantization Error')\n    ax2.set_title('Topographic Error')\n    ax1.set_xlabel('Epoch')\n    ax2.set_xlabel('Epoch')\n    ax1.grid(True)\n    ax2.grid(True)\n    plt.tight_layout()\n    return fig, ax1, ax2\n\n\n\nsource\n\n\nupdate_error_plots\n\n update_error_plots (fig:matplotlib.figure.Figure,\n                     ax1:matplotlib.axes._axes.Axes,\n                     ax2:matplotlib.axes._axes.Axes, epochs:list,\n                     qe_errors:list, te_errors:list,\n                     display_handle:&lt;function display&gt;)\n\nUpdate error plots\n\n\n\n\nType\nDetails\n\n\n\n\nfig\nFigure\nfigure\n\n\nax1\nAxes\nquantization error plot\n\n\nax2\nAxes\ntopographic error plot\n\n\nepochs\nlist\nepochs\n\n\nqe_errors\nlist\nquantization errors\n\n\nte_errors\nlist\ntopographic errors\n\n\ndisplay_handle\ndisplay\ndisplay handle\n\n\n\n\n\nExported source\ndef update_error_plots(\n    fig:plt.Figure, # figure\n    ax1:plt.Axes, # quantization error plot\n    ax2:plt.Axes, # topographic error plot\n    epochs:list, # epochs\n    qe_errors:list, # quantization errors\n    te_errors:list, # topographic errors\n    display_handle:display # display handle\n    ):\n    \"Update error plots\"\n    colors = ['#1c9e76', '#d95f01']\n    ax1.clear()\n    ax2.clear()\n    \n    ax1.plot(epochs, qe_errors, colors[0])\n    ax2.plot(epochs, te_errors, colors[1])\n    \n    ax1.set_title('Quantization Error (mse)', fontsize=12)\n    ax2.set_title('Topographic Error (%)', fontsize=12)\n    ax1.set_xlabel('Epoch', fontsize=10)\n    ax2.set_xlabel('Epoch', fontsize=10)\n    ax1.grid(True)\n    ax2.grid(True)\n    \n    plt.tight_layout()\n    display_handle.update(fig)\n\n\n\nsource\n\n\nSOM.fit\n\n SOM.fit (X:numpy.ndarray, n_epochs:int=20,\n          lr_scheduler:__main__.Scheduler=None,\n          sigma_scheduler:__main__.Scheduler=None, shuffle:bool=True,\n          verbose:bool=True, **kwargs)\n\nTrain the SOM on input data X\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nndarray\n\ndata matrix\n\n\nn_epochs\nint\n20\nnumber of epochs\n\n\nlr_scheduler\nScheduler\nNone\nlearning rate scheduler\n\n\nsigma_scheduler\nScheduler\nNone\nneighborhood radius scheduler\n\n\nshuffle\nbool\nTrue\nshuffle data\n\n\nverbose\nbool\nTrue\nverbose\n\n\nkwargs\n\n\n\n\n\nReturns\ntuple\n\ntuple of weights, quantization errors, and topographic errors\n\n\n\n\n\nExported source\n@patch\ndef fit(self:SOM, \n        X:np.ndarray, # data matrix\n        n_epochs:int=20, # number of epochs\n        lr_scheduler:Scheduler=None, # learning rate scheduler\n        sigma_scheduler:Scheduler=None, # neighborhood radius scheduler\n        shuffle:bool=True, # shuffle data\n        verbose:bool=True, # verbose\n        **kwargs # additional arguments\n        \n        )-&gt;tuple: # tuple of weights, quantization errors, and topographic errors\n    \"Train the SOM on input data X\"\n    if self.weights is None:\n        self.weights = self._initialize_weights(X, self.init)\n    \n    if lr_scheduler is None:\n        lr_scheduler = Scheduler(1.0, 0.01, 100, len(X), n_epochs)\n    if sigma_scheduler is None:\n        sigma_scheduler = Scheduler(max(self.grid_sz)/2, 1.0, 100, len(X), n_epochs)\n    \n    qe_errors, te_errors = [], []\n    epochs_data = []\n    mb = master_bar(range(n_epochs))\n    \n    # Setup displays\n    if verbose:\n        display_metrics = display(HTML(''), display_id='metrics')\n        fig, ax1, ax2 = setup_error_plots(**kwargs)\n        display_plots = display(fig, display_id='plots')\n        \n    for epoch in mb:\n        X_ = np.random.permutation(X) if shuffle else X.copy()\n        \n        for i, x in progress_bar(enumerate(X_), total=len(X_), parent=mb):\n            total_samples = epoch * len(X) + i\n            lr = lr_scheduler.step(total_samples)\n            sigma = sigma_scheduler.step(total_samples)\n            self._update_weights(x, lr, sigma)\n        \n        qe = self.quantization_error(X)\n        te = self.topographic_error(X)\n        qe_errors.append(qe)\n        te_errors.append(te)\n        \n        if verbose:\n            epochs_data.append((epoch, qe, te))\n            display_metrics.update(HTML(format_metrics_html(epochs_data)))\n            update_error_plots(fig, ax1, ax2, \n                               list(range(epoch + 1)), \n                               qe_errors, te_errors,\n                               display_plots)\n    \n    if verbose: plt.close(fig)  # Close the figure at the end\n    return self.weights, qe_errors, te_errors\n\n\n\nsource\n\n\nSOM.quantization_error\n\n SOM.quantization_error (X:numpy.ndarray)\n\nCalculate average distance between each input vector and its BMU\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\ndata matrix\n\n\nReturns\nfloat\nquantization error\n\n\n\n\n\nExported source\n@patch\ndef quantization_error(self:SOM, \n                       X:np.ndarray # data matrix\n                       )-&gt;float: # quantization error\n    \"Calculate average distance between each input vector and its BMU\"\n    return np.array([\n        self.dist_fn(x, self.weights).min() \n        for x in X\n    ]).mean()\n\n\n\nsource\n\n\nSOM.topographic_error\n\n SOM.topographic_error (X:numpy.ndarray)\n\nCalculate proportion of data vectors where 1st and 2nd BMUs are not adjacent\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\ndata matrix\n\n\nReturns\nfloat\ntopographic error\n\n\n\n\n\nExported source\n@patch\ndef topographic_error(self:SOM, \n                      X:np.ndarray # data matrix\n                      )-&gt;float: # topographic error\n    \"Calculate proportion of data vectors where 1st and 2nd BMUs are not adjacent\"\n    def _check_bmu_adjacency(x):\n        # Get indices of two best matching units\n        distances = self.dist_fn(x, self.weights)\n        flat_indices = np.argpartition(distances.flatten(), 2)[:2]\n        indices = np.unravel_index(flat_indices, self.grid_sz)\n        # Check if any coordinate differs by more than 1\n        return any(np.abs(x-y) &gt; 1 for x,y in indices)\n    \n    n_errors = sum(_check_bmu_adjacency(x) for x in X)\n    return (100 * n_errors) / len(X)  # Return percentage\n\n\n\nsource\n\n\nSOM.transform\n\n SOM.transform (X:numpy.ndarray)\n\nFind Best Matching Unit (BMU) coordinates for each input vector\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\ndata matrix\n\n\nReturns\nndarray\nbmu coordinates\n\n\n\n\n\nExported source\n@patch\ndef transform(self:SOM, \n              X:np.ndarray # data matrix\n              )-&gt;np.ndarray: # bmu coordinates\n    \"Find Best Matching Unit (BMU) coordinates for each input vector\"\n    bmu_coords = np.zeros((len(X), 2), dtype=int)\n    for i, x in enumerate(X):\n        bmu_coords[i] = self._find_bmu(x)\n    return bmu_coords\n\n\n\nsource\n\n\nSOM.predict\n\n SOM.predict (X:numpy.ndarray)\n\nAlias for transform method to follow sklearn convention\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\ndata matrix\n\n\nReturns\nndarray\nbmu coordinates\n\n\n\n\n\nExported source\n@patch  \ndef predict(self:SOM, \n            X:np.ndarray # data matrix\n            )-&gt;np.ndarray: # bmu coordinates\n    \"Alias for transform method to follow sklearn convention\"\n    return self.transform(X)\n\n\n\nsource\n\n\nSOM.umatrix\n\n SOM.umatrix ()\n\nReturn the U-Matrix for current weights\n\n\nExported source\n@patch  \ndef _calculate_umatrix(self:SOM)-&gt;np.ndarray:\n    \"Calculate U-Matrix values for current weights\"\n    def _neighbor_distances(pos):\n        # Offsets for 8 neighbors\n        nbr_offsets = [\n            (-1,-1), (-1,0), (-1,1),  # top-left, top, top-right\n            (0,-1),          (0,1),   # left, right\n            (1,-1),  (1,0),  (1,1)    # bottom-left, bottom, bottom-right\n        ]\n    \n        distances = []\n        weights = []\n        for dr, dc in nbr_offsets:\n            r, c = pos\n            nbr_r, nbr_c = r+dr, c+dc\n            if (nbr_r &gt;= 0 and nbr_r &lt; self.grid_sz[0] and \n                nbr_c &gt;= 0 and nbr_c &lt; self.grid_sz[1]):\n                w = 1/np.sqrt(dr**2 + dc**2)  # weight by distance\n                weights.append(w)\n                d = self.dist_fn(self.weights[r,c], self.weights[nbr_r,nbr_c])\n                distances.append(d)\n        return np.average(distances, weights=weights)\n        \n    umatrix = np.zeros(self.grid_sz)\n    for i, j in np.ndindex(self.grid_sz):\n        umatrix[i,j] = _neighbor_distances((i,j))\n    return umatrix\n\n\n\n\nExported source\n@patch\ndef umatrix(self:SOM)-&gt;np.ndarray:\n    \"Return the U-Matrix for current weights\"\n    return self._calculate_umatrix()\n\n\n\nsource\n\n\nSOM.plot_umatrix\n\n SOM.plot_umatrix (figsize=(8, 6), cmap='viridis_r')\n\nPlot U-Matrix visualization\n\n\nExported source\n@patch\ndef plot_umatrix(self:SOM, \n                 figsize=(8,6), \n                 cmap='viridis_r'):\n    \"Plot U-Matrix visualization\"\n    plt.figure(figsize=figsize)\n    plt.imshow(self.umatrix(), cmap=cmap, interpolation='nearest')\n    plt.colorbar(label='Average distance to neighbors')\n    plt.title('U-Matrix')\n    plt.tight_layout();\n\n\n\n# Load and normalize MNIST data\nfrom sklearn.datasets import load_digits\n\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Create and train SOM\nsom = SOM(grid_sz=(20,20), input_dim=64, init='pca')\n_ = som.fit(X_norm, n_epochs=10, verbose=True)\nsom.plot_umatrix(figsize=(4,4))\n\n\n    \n        Training Progress\n        \n\n\n\nEpoch\nQE\nTE\n\n\n1\n1.9729\n2.7268\n\n\n2\n1.8512\n1.5025\n\n\n3\n1.7220\n0.7234\n\n\n4\n1.5898\n0.4452\n\n\n5\n1.4855\n0.5565\n\n\n6\n1.3933\n0.6678\n\n\n7\n1.3253\n0.2782\n\n\n8\n1.2618\n0.3895\n\n\n9\n1.2168\n0.3339\n\n\n10\n1.1855\n0.4452",
    "crumbs": [
      "Source",
      "core"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html",
    "href": "workflow/how-was-it-created.html",
    "title": "How was it created?",
    "section": "",
    "text": "Reference: Self-Organizing Map (Kohonen)",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#problem-statement",
    "href": "workflow/how-was-it-created.html#problem-statement",
    "title": "How was it created?",
    "section": "",
    "text": "Reference: Self-Organizing Map (Kohonen)",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#table-of-contents",
    "href": "workflow/how-was-it-created.html#table-of-contents",
    "title": "How was it created?",
    "section": "Table of Contents",
    "text": "Table of Contents\nNB: Generated a posteriori\nI. CORE SOM COMPONENTS\n\nI.1 Weight Grid Initialization\nI.2 Distance Metrics\nI.3 BMU (Best Matching Unit)\nI.4 Neighborhood Function\nI.5 Weight Update Rule\n\n\nEXTENDED TRAINING COMPONENTS\n\n\nII.1 A 2D Toy Dataset\nII.2 U-Matrix\nII.3 Naive Training Loop\nII.4 Quantization Error (QE)\nII.5 Topographic Error (TE)\nII.6 LR and σ Schedulers\nII.7 Advanced Training Loop with Schedulers\nII.8 Revised Plan\n\n\nWEIGHTS INITIALIZATION METHODS\n\n\nIII.1 Random Initialization\nIII.2 PCA Initialization\n\n\nADDITIONAL VISUALIZATIONS\n\nV. REFACTORING\n\nV.1 Class Implementation\nV.2 README.md\n\nAI Prompt\nI want to create an Python package implementing a Self Organizing Map. Several Python packages already exist but I would prefer creating it from scratch to be sure to understand every single piece.\nThe SOM implementation will be flexible and accept different distance metrics, learning rate and gaussian radius schedulers and assess SOM’s quality using relevant metrics.\nI want to comply with Polya’s “How to solve it framework”.\nI want also to make sure it uses numpy vectorization everywhere possible and use fastcore.\nRefactoring as class should come at the end.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nI’ll help you create a Self-Organizing Map (SOM) implementation from scratch. Let’s follow Polya’s framework step by step.\n\nFirst, let’s understand the problem:\n\nCan you tell me your current familiarity with SOMs and what specific aspects you want to focus on?\nAre you comfortable with numpy vectorization?\nDo you have experience with fastcore?\n\n\nThis will help me tailor the guidance to your needs and ensure we build on your existing knowledge.\nAlso, before we proceed, could you outline which distance metrics and quality assessment measures you’re particularly interested in implementing? This will help us plan the architecture effectively.\n\n\nAI Prompt\nLet me try reformulating the SOM’s approach and tell me if my understanding is correct.\nWe have a grid of (random - but could be informed by data itself) weights (same dimension of the input).\nFor each sample of our training set, we want to find the weight most similar to the input (bmu - best matching unit in SOM’s jargon).\nOnce found we define a neighorhood function that essentially equal to 1 at the grid index of the bmu and decays/vanishes as further away from the bmu, as parametrized by a gaussian function with parameter sigma (to define a notion of “locality”).\nThen the objective is to “pull” all weights toward this individual input but proportionaly to this neighborhood function. It means that we take the difference between the given input and the weights, and update the weights according to those differences and the neighborhood function.\nA learning rate parameter also allow to specifify how quickly we want to update the weights for each sample.\nWhat do you think? Did I capture the key concepts?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, that’s an excellent and accurate description of the SOM algorithm! Let me highlight the key components you’ve identified:\n\nGrid of weights (prototype vectors)\n\nInitialize randomly (or with PCA/other informed methods)\nSame dimensionality as input data\n\nBest Matching Unit (BMU)\n\nFor each input, find closest weight vector\nRequires distance metric (commonly Euclidean)\n\nNeighborhood function\n\nGaussian decay from BMU location\nControlled by sigma parameter (radius)\nDefines “influence zone” on grid\n\nWeight update rule\n\nPull weights towards input\nStrength determined by:\n\nLearning rate (overall step size)\nNeighborhood function (locality-based influence)\n\n\n\nWould you like to start breaking this down into smaller implementation steps? We could begin by focusing on one of these components. Which part would you like to tackle first?",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#i.-core-som-components",
    "href": "workflow/how-was-it-created.html#i.-core-som-components",
    "title": "How was it created?",
    "section": "I. CORE SOM COMPONENTS",
    "text": "I. CORE SOM COMPONENTS\n\nI.1 Weight grid\n\nimport numpy as np\ngrid_sz = (3,3)\nws = np.random.randn(*grid_sz)\nws.shape, ws\nws.shape, ws\n\n((3, 3),\n array([[-1.361616  , -0.47049376, -0.95493151],\n        [ 1.41949963, -0.01988135, -1.88250715],\n        [-0.41864399, -1.87207718, -0.51610482]]))\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(3, 2))  # Compact figure size\nplt.rcParams.update({'font.size': 6})  # Base font size\n\n# Create meshgrid for plotting\nx, y = np.meshgrid(range(grid_sz[0]), range(grid_sz[1]))\n\nplt.scatter(x, y, c=ws, s=100, cmap='viridis')  \nplt.colorbar(label='Weight values')\n\nplt.grid(True)\nplt.title('2D SOM Grid Initial Weights', fontsize=6)\nplt.xlabel('X coordinate', fontsize=6)\nplt.ylabel('Y coordinate', fontsize=6)\nplt.xticks(fontsize=6)\nplt.yticks(fontsize=6)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nI.2 Distance\n\nws = np.random.randn(3,3,200)\nws.shape\n\n(3, 3, 200)\n\n\n\nX = np.random.randn(100,200)\nX.shape\n\n(100, 200)\n\n\n\nX[0].shape\n\n(200,)\n\n\nAI Prompt\nEach node of the grid (here 3x3) has a weight of 200 dimensions in our toy example. How to take the euclidean distance between each weight and a 200-dimensional input?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nLet’s think about this vectorized approach:\n\nFor Euclidean distance, we need √(Σ(x-w)²) between:\n\nOne input vector (1, 200)\nAll weight vectors (3, 3, 200)\n\n\nWe have two main vectorized approaches we could use: 1. Using numpy broadcasting and np.sum 2. Using scipy’s cdist (which handles this specific case)\nWould you like to try implementing one of these approaches? I can guide you through the numpy broadcasting solution first if you’d like, or we can discuss the trade-offs between the two approaches.\nWhich would you prefer to explore first?\n\n\nNumpy will broadcast the 1-dimensioal input vector of shape (200,) to (3,3,200) to align it to the weights shape. We want the distance between each unit (200-dimensional in our toy example) and the given input. There are two ways to do so. Either using native numpy or …\n\n# Element-wise distance between each `(200,)` node/weights and the input.\n(X[0]-ws).shape\n\n(3, 3, 200)\n\n\n\n# Now we take the root square of the square distance element-wise and take their sum along the last dimension (200)\nnp.sqrt(np.sum((X[0]-ws)**2, axis=-1))\n\narray([[17.91644487, 19.40803926, 18.10014622],\n       [18.92468523, 19.64872772, 21.76170238],\n       [21.98737528, 20.59933278, 19.29730677]])\n\n\n\n# We can do it also using numpy dedicated method\nnp.linalg.norm(ws-X[0], axis=-1)\n\narray([[17.91644487, 19.40803926, 18.10014622],\n       [18.92468523, 19.64872772, 21.76170238],\n       [21.98737528, 20.59933278, 19.29730677]])\n\n\n\n# This is to be injected into the final class for further flexibility\ndist_fn = lambda x, ws: np.linalg.norm(ws-x, axis=-1)\ndist_fn(X[0], ws)\n\narray([[17.91644487, 19.40803926, 18.10014622],\n       [18.92468523, 19.64872772, 21.76170238],\n       [21.98737528, 20.59933278, 19.29730677]])\n\n\n\n\nI.3 BMU (Best Matching Unit)\nAI Prompt\nI’d like to find the closest unit/node from a given input and want to return its index.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nTo find the BMU index, we need to: 1. Get the distances (which we already calculated) 2. Find the index of the minimum distance in our 2D grid\nWe can use np.argmin(), but since we have a 2D grid, we’ll need to consider how to handle the indices. Would you like to try implementing this yourself, or would you like me to suggest an approach?\nA key consideration is whether you want: - A flat index (single number) - Grid coordinates (row, col)\nWhich format would be more useful for your implementation?\n\n\nAI Prompt\nI want to find the grid coordinates but np.argmin() seems to work only for flatten arrays.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nAh yes! For 2D coordinates, we can use np.unravel_index() together with np.argmin(). This combination will:\n\nnp.argmin() finds the index in the flattened array\nnp.unravel_index() converts this flat index back to grid coordinates\n\nWould you like to try implementing this yourself using these functions? I can provide more details about how np.unravel_index() works if needed.\n\n\n\nnp.random.seed(1)\nws = np.random.randn(2,2,1)\nx = np.array(0.5)\nd = dist_fn(X[0], ws)\nprint(x, '\\n', d)\nnp.argmin(d)\n\n0.5 \n [[27.38521073 16.09891829]\n [15.54144978 20.16819721]]\n\n\n2\n\n\n\nnp.unravel_index(2,shape=ws.shape[:2])\n\n(1, 0)\n\n\nSo, finding the grid index of the smallest distance is as simple as taking the np.argmin (internally flattening the array) and then using np.unravel_index with grid shape specified:\n\ndef bmu_coords(dists, sz):\n    return np.unravel_index(np.argmin(dists), sz)\n\nbmu_coords(dist_fn(X[0], ws), ws.shape[:2])\n\n(1, 0)\n\n\n\n\nI.4 Create neighborhood function\nAI Prompt\nLet me try to recap and reformulate the role of the neighborhood function with my own words. The weights update will be carried out according to the following logic: 1. we first get the distance between a given input and all units/nodes 2. the closest unit is called the bmu 3. Each unit will be then updated as a function of: - its distance from the given input - but also of its “decayed” distance of its grid index from the bmu - by “decayed” we mean that using a gaussian function parametrized by a “radius of influence” or a “degree of locality”, we update the units close from the bmu more than the distant one.\nHence the neighborhood function, should return for a given node a coefficient that will be used to further weigh the weights update. Last, it is important to note that this update will be further parametrized by a learning rate lr.\nIs my thinking correct?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, your understanding is excellent! You’ve captured all the key aspects of the neighborhood function and its role in weight updates. Let me confirm each point:\n\n✓ Calculate distances & find BMU\n✓ For each unit, weight update depends on:\n\nDistance from input (the error term)\nDistance from BMU on the grid (neighborhood influence)\nGaussian decay based on grid distance (controlled by radius σ)\n\n✓ Final update magnitude determined by:\n\nNeighborhood coefficient (from gaussian)\nLearning rate (lr)\n\n\nWould you like to start implementing the neighborhood function? We’ll need to: 1. Calculate grid distances from BMU to all nodes 2. Apply gaussian decay to these distances\nWhich part would you like to tackle first?\n\n\n\nws = np.random.randn(3,4,1)\nbmu_idx = (2,2)\n\n\n# 1 row, 3 cols\na = np.array([\n    [1,2,3,4]\n    ])\na.shape\n\n(1, 4)\n\n\n\n# 3 rows, 1 col\nb = np.array([\n    [10],\n    [20],\n    [30]\n    ])\nb.shape\n\n(3, 1)\n\n\n\n# (3, 1) + (1, 4) -&gt; (3,4)\n# or (1, 4) + (3, 1) -&gt; (3, 4)\n\n\na + b\n\narray([[11, 12, 13, 14],\n       [21, 22, 23, 24],\n       [31, 32, 33, 34]])\n\n\n\nb + a\n\narray([[11, 12, 13, 14],\n       [21, 22, 23, 24],\n       [31, 32, 33, 34]])\n\n\n\nbmu_idx\n\n(2, 2)\n\n\nAI Prompt\nFrom the (3,4) shape I’d like to create two numpy arrays: one of shape (1,4) with the following values [0,1,2,3] (the rows idx) and one of shape (3,1) with the following values [0,1,2]. From those arrays, I then want to calculate the delta x and delta y from the bmu coordinates to eventually get a neighborhood function then I’d further weigh by a gaussian kernel. Can you guide me?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nI’ll help you step by step:\n\nFirst, let’s create those two arrays using np.arange():\n\nx_coords = np.arange(4).reshape(1, 4)  # [0,1,2,3] shape (1,4)\ny_coords = np.arange(3).reshape(3, 1)  # [0,1,2] shape (3,1)\nWould you like to try this first and then we can move on to calculating the deltas from the BMU coordinates?\nThe next step would be subtracting the BMU’s x and y coordinates from these arrays. Would you like to try that yourself, or would you like more guidance?\n\n\nAI Prompt\nIsn’t there a more straightforward to get those x and y coords directly from the shape (3,4) using a dedicated numpy method?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nAh yes! You can use np.meshgrid() to directly generate coordinate arrays from the shape. This function is specifically designed for creating coordinate matrices. Would you like to explore how to use np.meshgrid() for this purpose?\nLet me know if you want to try it yourself first, or if you’d like me to show you how it works with your (3,4) shape example.\n\n\nAI Prompt\nI’ve heard about this method: np.ogrid[0:grid_sz[0], 0:grid_sz[1]] Don’t you think it would be more convenient?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, absolutely! np.ogrid is a more concise and elegant solution for this case. It creates an “open mesh” which is exactly what we need - two arrays suitable for broadcasting, without actually storing the full mesh in memory.\nWould you like to try using np.ogrid to: 1. Create the coordinate arrays 2. Calculate the deltas from the BMU position\nWhich step would you like to tackle first?\n\n\n\nx_coords, y_coords = np.ogrid[0:ws.shape[0], 0:ws.shape[1]]\nx_coords, y_coords\n\n(array([[0],\n        [1],\n        [2]]),\n array([[0, 1, 2, 3]]))\n\n\n\nbmu_idx, bmu_idx[0] - x_coords\n\n((2, 2),\n array([[2],\n        [1],\n        [0]]))\n\n\n\nbmu_idx[1] - y_coords\n\narray([[ 2,  1,  0, -1]])\n\n\n\n(bmu_idx[0] - x_coords)**2 + (bmu_idx[1] - y_coords)**2\n\narray([[8, 5, 4, 5],\n       [5, 2, 1, 2],\n       [4, 1, 0, 1]])\n\n\n\ndef grid_dist2(bmu_idx, grid_sz):\n    rows_idx, cols_idx = np.ogrid[0:grid_sz[0], 0:grid_sz[1]]\n    return (bmu_idx[0] - rows_idx)**2 + (bmu_idx[1] - cols_idx)**2\n\ngrid_dist2(bmu_idx, ws.shape[:2])\n\narray([[8, 5, 4, 5],\n       [5, 2, 1, 2],\n       [4, 1, 0, 1]])\n\n\nAI Prompt\nI think that now suffices to pass this array to a Gaussian function to create our neighborhood function, don’t you think?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, exactly! We can create a Gaussian decay function using np.exp(-dist²/(2σ²)), where: - dist² is what we just calculated - σ (sigma) is our radius parameter that controls the spread of the neighborhood\nWould you like to try implementing this Gaussian function? We’ll need to: 1. Take our squared distances 2. Apply the Gaussian formula with a sigma parameter\nWould you like to try this yourself, or would you like some guidance on the implementation?\n\n\n\ngaussian_fn = lambda dists, sigma: np.exp(-dists/(2*sigma**2))\ngaussian_fn(grid_dist2(bmu_idx, ws.shape[:2]), 1)\n\narray([[0.01831564, 0.082085  , 0.13533528, 0.082085  ],\n       [0.082085  , 0.36787944, 0.60653066, 0.36787944],\n       [0.13533528, 0.60653066, 1.        , 0.60653066]])\n\n\n\nfrom functools import partial\ndef neighborhood_fn(dists, kernel_fn):\n    return kernel_fn(dists)\n    \ndists = grid_dist2(bmu_idx, ws.shape[:2])\nkernel_fn = partial(gaussian_fn, sigma=1)\nneighborhood_fn(dists, kernel_fn)\n\narray([[0.01831564, 0.082085  , 0.13533528, 0.082085  ],\n       [0.082085  , 0.36787944, 0.60653066, 0.36787944],\n       [0.13533528, 0.60653066, 1.        , 0.60653066]])\n\n\n\n\nI.5 Implement weight update rule\nAI Prompt\nLet me reformulate the weight update rule. Given an input, the SOM weights/nodes/units will be updated as follows: 1. compute the distance between the input and all weights/nodes/units, d 2. compute the distance from the bmu position from all other grids/weights position d_grid`` 3.w_new = w + lrdneighborhood_fn(d_grid) where lr is the learning rate\nIn summary at every iteration (new sample), we pull all weights and their surroundings (as defined by the neighborhood function) toward the input (the bmu weights being the most affected).\nAm I right?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, your understanding is perfect! Let me break down your correct formulation:\nFor each input sample: 1. ✓ Calculate distances between input and all weights 2. ✓ Find BMU (closest weight) 3. ✓ Calculate grid distances from BMU position 4. ✓ Apply neighborhood function to grid distances 5. ✓ Update weights using the formula: w_new = w + lr * (input - w) * neighborhood_fn(d_grid)\nOne small clarification to your formula: the d term should be (input - w), representing the direction and magnitude of the update.\nWould you like to try implementing this update rule? We can break it down into steps if you’d like.\n\n\nLet’s do it step-by-step while checking shapes “compatibility” for numpy broadcasting.\n\nws = np.random.randn(2,2,3)\nx = np.array([0.5, 0.1, 0.2])\n(x-ws).shape\n\n(2, 2, 3)\n\n\n\n# Define kernel function with wanted parameter\nkernel_fn = partial(gaussian_fn, sigma=1)\n# Get bmu position\nbmu_idx = bmu_coords(dist_fn(x, ws), ws.shape[:2])\n# Compute neighborhood weights for each unit\nnbh = neighborhood_fn(grid_dist2(bmu_idx, ws.shape[:2]), kernel_fn)\nnbh.shape\n\n(2, 2)\n\n\nThe neighborhood will weigh eacg node’s update give its distance from the bmu and provided kernel functions. So we want an element-wised multiplication between this 2x2array and the first two dimensions of the (x-ws) differences. Hence to be able to use numpy broadasting we have to add an additional trailing dimension to the neighborhood.\n\nnbh[..., np.newaxis].shape\n\n(2, 2, 1)\n\n\n\n(nbh[..., np.newaxis] * (x-ws)).shape\n\n(2, 2, 3)\n\n\nWe now have all components required to define the update function.\n\nlr = 1\nws = np.random.randn(2,2,3)\nx = np.array(0.5)\n\nd = dist_fn(x, ws)\nbmu_idx = bmu_coords(d, ws.shape[:2])\nd_grid = grid_dist2(bmu_idx, ws.shape[:2])\nkernel_fn = partial(gaussian_fn, sigma=1)\nnbh = neighborhood_fn(grid_dist2(bmu_idx, ws.shape[:2]), kernel_fn)\n\nws + lr * (nbh[..., np.newaxis] * (x-ws))\n\narray([[[ 0.01460216,  0.51918831, -0.25327326],\n        [ 0.14715498,  0.03288394, -0.02929718]],\n\n       [[ 0.03915056,  0.2982822 , -0.13636204],\n        [ 0.5       ,  0.5       ,  0.5       ]]])\n\n\n\ndef update(x, ws, dist_fn, kernel_fn, lr=1):\n    bmu_idx = bmu_coords(dist_fn(x, ws), ws.shape[:2])\n    d_grid = grid_dist2(bmu_idx, ws.shape[:2])\n    nbh = neighborhood_fn(grid_dist2(bmu_idx, ws.shape[:2]), kernel_fn)\n    return ws + lr * nbh[..., np.newaxis] * (x-ws)\n\nws = np.random.randn(2,2,3)\nx = np.array([0.5, 0.1, 0.2])\nkernel_fn = partial(gaussian_fn, sigma=1)\nupdate(x, ws, dist_fn, kernel_fn, lr=1)\n\narray([[[ 0.06267652, -0.52430057, -0.39871823],\n        [ 0.96919433,  0.08064436, -0.12933212]],\n\n       [[ 0.37838472,  0.88703907,  0.168585  ],\n        [ 0.5       ,  0.1       ,  0.2       ]]])\n\n\n\nws = np.array([\n    [[1], [2]], \n    [[3], [4]\n    ]])\nnp.squeeze(ws) # squeeze the trailing dim for clearer printing\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nx = np.array(3.8)\nnp.squeeze(update(x, ws, dist_fn, kernel_fn, lr=1))\n\narray([[2.03006244, 3.09175519],\n       [3.48522453, 3.8       ]])\n\n\nOk, we observe that the SOM’s nodes are pulled toward the bmu accordingly. We have all core SOM compoenents, we can implement now the training loop.\n\n\nI.6 Revised plan\nAI Prompt\nI think that should be pretty straightforward to implement. We know how to update the SOM/weights for every single data point. It suffices to iterate over the training set multiple times (epochs) until we think this is enough right?\nObviously it raises a couple of questions. First usually, the learning rate and for instance the gaussian kernel sigma are decayed during training. Second, after each epoch (one pass over the train set), we’d like to log some metrics (Quantization error and Topographic error). Also, I think that would be very useful if we could visualize how the SOM improves as we add new features like scheduled learning rate and gaussian kernel sigma. Hence, I’d like to implement a U-Matrix visualization in priority. So I think we have to slightly revised the initial plan (shown below) to take into account both decay, metrics and U-matrix now as it is interleaved with the training loop. Ideally, we should implement second the training loop but implement in this main step also U-Matrix visualization, … so that we can see how the training loop, training loop + scheduler affect the training visually.\nInitial plan: Following Polya’s framework, let’s create a structured plan. Here’s a suggested breakdown - please let me know if you’d like to modify any part:\n\nCore SOM Components\n\nInitialize weight grid (DONE)\nImplement distance metrics (Euclidean first, others later) (DONE)\nFind BMU function (DONE)\nCreate neighborhood function (DONE)\nImplement weight update rule (DONE)\n\nTraining Loop\n\nSingle sample update (DONE)\nFull epoch processing\nLearning rate scheduling\nRadius (sigma) scheduling\n\nQuality Metrics\n\nQuantization error\nTopographic error\nOther quality measures\n\nUtilities & Visualization\n\nGrid visualization\nU-Matrix\nComponent planes\n\nRefactoring\n\nCreate class structure\nAdd flexibility for different metrics/schedulers\nDocumentation\n\n\nPlease adjust the plan accordingly.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYou make excellent points! Yes, we should revise the plan to better integrate visualization and metrics with the training loop, since they’re crucial for understanding how the SOM evolves. Here’s a suggested revision:\n\nCore SOM Components (DONE)\n\n✓ Initialize weight grid\n✓ Distance metrics\n✓ BMU function\n✓ Neighborhood function\n✓ Weight update rule\n\nExtended Training Components\n\nTraining loop structure\nU-Matrix visualization (moved up from 4)\nBasic quality metrics (moved up from 3)\nLearning rate scheduler\nRadius scheduler\nTraining progress visualization\n\nAdditional Quality Metrics\n\nQuantization error\nTopographic error\nCustom metrics interface\n\nAdditional Visualizations\n\nComponent planes\nCustom visualization options\n\nRefactoring\n\nClass structure\nFlexible interfaces\nDocumentation\n\n\nWould you like to start with implementing the training loop along with U-Matrix visualization so you can see the SOM’s evolution during training?",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#ii.-extended-training-components",
    "href": "workflow/how-was-it-created.html#ii.-extended-training-components",
    "title": "How was it created?",
    "section": "II. EXTENDED TRAINING COMPONENTS",
    "text": "II. EXTENDED TRAINING COMPONENTS\nLet’s first implementing a training (fit) loop to see where and how scheduling should take place.\n\nII.1 A 2D toy dataset\n\n!pip3 install scikit-learn\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: scikit-learn in ./.local/lib/python3.11/site-packages (1.6.0)\nRequirement already satisfied: numpy&gt;=1.19.5 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.26.3)\nRequirement already satisfied: scipy&gt;=1.6.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in ./.local/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in ./.local/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.3.1\n[notice] To update, run: pip install --upgrade pip\n\n\n\nfrom sklearn.datasets import make_blobs, make_moons, make_swiss_roll\nX, y = make_blobs(n_samples=1_000, centers=3, cluster_std=0.5, random_state=0)\n\n\nplt.figure(figsize=(2,2))\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=3)\nplt.title(\"Three normally-distributed clusters\")\nplt.show()\n\n\n\n\n\n\n\n\n\nX.shape\n\n(1000, 2)\n\n\n\nn_nodes = lambda n_samples: int(np.sqrt(5*np.sqrt(n_samples)))\nn_nodes(200)\n\n8\n\n\n\nn_samples = len(X)\ngrid_sz = (n_nodes(n_samples),n_nodes(n_samples))\nws = np.random.randn(*grid_sz, X.shape[-1])\nws.shape\n\n(12, 12, 2)\n\n\n\n\nII.2 U-Matrix\nAI Prompt\nI’d like to create a U-Matrix visualization. Correct me if I am wrong but my understanding is the following: - for each unit/node, we compute the average or sum of the distances between the node and its neighbours (from 2 for the corners to 3 at the edges and 4 for the others) - we then represent those aggregated “surrounding” distances in the grid - it can be interpreted as follows (when bright is small distance and dark is large distance): a group of bright nodes surrounded by dark ones suggest a cluster\nAm I right?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, your understanding of the U-Matrix (Unified Distance Matrix) is correct! Let me confirm each point:\n\n✓ For each node:\n\nCalculate distances to immediate neighbors\nCan have 2 neighbors (corners)\nCan have 3 neighbors (edges)\nCan have 4 neighbors (interior nodes)\n\n✓ Visualization shows:\n\nAverage/sum of distances to neighbors\nUsually displayed as a heatmap\n\n✓ Interpretation:\n\nBright regions = similar nodes = potential cluster\nDark regions = dissimilar nodes = potential boundaries\nDark “barriers” between bright regions suggest cluster boundaries\n\n\nWould you like to implement this visualization? We’ll need to: 1. Create a function to find neighbors for each node 2. Calculate distances between neighbors 3. Create the visualization\nWhich part would you like to tackle first?\n\n\n\n# Test weights matrix (SOM)\nx = np.array([\n    [[1], [3], [1]],\n    [[11], [4], [2]],\n    [[7], [8], [5]]])\n\nnp.squeeze(x)\n\narray([[ 1,  3,  1],\n       [11,  4,  2],\n       [ 7,  8,  5]])\n\n\nI first attempted an approach using vectorization, padded and masked version of the weights. I am finding cluncky and much less readable than a more straightforward iteration throughout the weights.\n\n# For instance a right-padded version of test weights matrix\nx_right = np.pad(x, ((0,0), (0,1), (0,0)), mode='edge')\nd_right = np.linalg.norm(x_right[:,1:] - x_right[:,0:-1], axis=-1)\nd_right\n\narray([[2., 2., 0.],\n       [7., 2., 0.],\n       [1., 3., 0.]])\n\n\nBelow, an iterative approach:\n\n# Neighbors offsets\nnbr_offsets = [\n    (-1,-1), (-1,0), (-1,1),  # top-left, top, top-right\n    (0,-1),          (0,1),   # left, right\n    (1,-1),  (1,0),  (1,1)    # bottom-left, bottom, bottom-right\n]\n\n\nn_rows, n_cols = 3,3\npos = (0,1)\n_ws = []\nds = []\nfor dr,dc in nbr_offsets:\n    r,c = pos\n    nbr_r, nbr_c = r+dr, c+dc\n    if (nbr_r&gt;=0 and nbr_r&lt;n_rows) and (nbr_c&gt;=0 and nbr_c&lt;n_cols):\n        w = 1/np.sqrt(dr**2 + dc**2)\n        _ws.append(w)\n        d = np.linalg.norm(x[r, c] - x[nbr_r, nbr_c], axis=-1)\n        ds.append(d)\n        print(f'distance between: {r,c} and {nbr_r, nbr_c}: {d} with weight: {w:.2f}')\n\nnp.average(ds, weights=_ws)\n\ndistance between: (0, 1) and (0, 0): 2.0 with weight: 1.00\ndistance between: (0, 1) and (0, 2): 2.0 with weight: 1.00\ndistance between: (0, 1) and (1, 0): 8.0 with weight: 0.71\ndistance between: (0, 1) and (1, 1): 1.0 with weight: 1.00\ndistance between: (0, 1) and (1, 2): 1.0 with weight: 0.71\n\n\n2.5744021828816153\n\n\n\ndef is_in_bounds(row_idx, col_idx, ws):\n    n_rows, n_cols = ws.shape[:2]\n    return  (row_idx&gt;=0 and row_idx&lt;n_rows) and (col_idx&gt;=0 and col_idx&lt;n_cols) \n\nprint(is_in_bounds(0,0,x))\nprint(is_in_bounds(-1,0,x))\nprint(is_in_bounds(4,0,x))\n\nTrue\nFalse\nFalse\n\n\n\ndef nbr_dist(pos, ws, dist_fn, nbr_offsets=nbr_offsets):\n    weights = []\n    ds = []\n    for dr,dc in nbr_offsets:\n        r,c = pos\n        nbr_r, nbr_c = r+dr, c+dc\n        if is_in_bounds(nbr_r, nbr_c, ws):\n            weights.append(1/np.sqrt(dr**2 + dc**2))\n            d = dist_fn(ws[r, c] - ws[nbr_r, nbr_c], axis=-1)\n            ds.append(d)\n\n    return np.average(ds, weights=weights)\n\npos = (0,1)\nnbr_dist(pos, x, np.linalg.norm)\n\n2.5744021828816153\n\n\n\nnp.squeeze(x)\n\narray([[ 1,  3,  1],\n       [11,  4,  2],\n       [ 7,  8,  5]])\n\n\n\nu_matrix = np.zeros(x.shape[:2])\nfor i, j in np.ndindex(x.shape[:2]):\n    u_matrix[i,j] = nbr_dist((i,j), x, np.linalg.norm)\n\nu_matrix\n\narray([[5.21638838, 2.57440218, 1.89180581],\n       [6.51943414, 3.08578644, 2.48056586],\n       [2.63060194, 3.25402494, 2.47759225]])\n\n\n\ndef calculate_umatrix(weights, dist_fn=np.linalg.norm):\n    u_matrix = np.zeros(weights.shape[:2])\n    for i, j in np.ndindex(weights.shape[:2]):\n        u_matrix[i,j] = nbr_dist((i,j), weights, dist_fn)\n    return u_matrix\n\ncalculate_umatrix(x)\n\narray([[5.21638838, 2.57440218, 1.89180581],\n       [6.51943414, 3.08578644, 2.48056586],\n       [2.63060194, 3.25402494, 2.47759225]])\n\n\n\ndef plot_umatrix(weights, cmap='viridis_r', figsize=(2,2)):\n    umatrix = calculate_umatrix(weights)\n    plt.figure(figsize=figsize)\n    plt.imshow(umatrix, cmap=cmap, interpolation='nearest')\n    plt.colorbar(label='Average distance to neighbors')\n    plt.title('U-Matrix')\n    plt.show()\n\nplot_umatrix(ws)\n\n\n\n\n\n\n\n\n\n\nII.3 Naive training loop\n\nfrom tqdm import trange, tqdm\nn_epochs = 20\nfor epoch in tqdm(range(n_epochs)):\n    X_ = np.random.permutation(X)\n    for x in X:\n        kernelf_fn = partial(gaussian_fn, sigma=1)\n        ws = update(x, ws, dist_fn, kernel_fn, lr=0.1)\n\n\n  0%|          | 0/20 [00:00&lt;?, ?it/s]\n  5%|5         | 1/20 [00:00&lt;00:02,  7.25it/s]\n 10%|#         | 2/20 [00:00&lt;00:02,  7.38it/s]\n 15%|#5        | 3/20 [00:00&lt;00:02,  7.51it/s]\n 20%|##        | 4/20 [00:00&lt;00:02,  7.57it/s]\n 25%|##5       | 5/20 [00:00&lt;00:01,  7.55it/s]\n 30%|###       | 6/20 [00:00&lt;00:01,  7.54it/s]\n 35%|###5      | 7/20 [00:00&lt;00:01,  7.58it/s]\n 40%|####      | 8/20 [00:01&lt;00:01,  7.58it/s]\n 45%|####5     | 9/20 [00:01&lt;00:01,  7.58it/s]\n 50%|#####     | 10/20 [00:01&lt;00:01,  7.54it/s]\n 55%|#####5    | 11/20 [00:01&lt;00:01,  7.56it/s]\n 60%|######    | 12/20 [00:01&lt;00:01,  7.57it/s]\n 65%|######5   | 13/20 [00:01&lt;00:00,  7.55it/s]\n 70%|#######   | 14/20 [00:01&lt;00:00,  7.50it/s]\n 75%|#######5  | 15/20 [00:01&lt;00:00,  7.54it/s]\n 80%|########  | 16/20 [00:02&lt;00:00,  7.58it/s]\n 85%|########5 | 17/20 [00:02&lt;00:00,  7.55it/s]\n 90%|######### | 18/20 [00:02&lt;00:00,  7.54it/s]\n 95%|#########5| 19/20 [00:02&lt;00:00,  7.55it/s]\n100%|##########| 20/20 [00:02&lt;00:00,  7.57it/s]\n100%|##########| 20/20 [00:02&lt;00:00,  7.54it/s]\n\n\n\nplot_umatrix(ws)\n\n\n\n\n\n\n\n\nAI Prompt\nGreat, we clearly see the 3 clusters captured. Now I’d like to implement some of the metrics: Quantization Error and Topographic Error so that to log it after every epoch ideally.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nLet’s implement these two metrics:\n\nQuantization Error (QE):\n\nAverage distance between each input vector and its BMU\nMeasures how well the map represents the input space\n\nTopographic Error (TE):\n\nProportion of data vectors for which 1st and 2nd BMUs are not adjacent\nMeasures preservation of topology\n\n\nWould you like to implement these metrics one at a time? We can start with the Quantization Error since it’s simpler and uses components we already have (distance function and BMU finding).\nWhich metric would you prefer to tackle first?\n\n\n\n\nII.4 Quantization Error (QE)\nAI Prompt\nHere is my understanding and plan to calculate QE (Quantization Error) For each sample of the training set we have to: - identify its bmu (we already have a function for this) - calculate input/sample distance from its bmu (we have this already) - take the mean of those distances\nActually when we search the bmu, we take the argmin of the distances between each node/unit and the input. Here, we don’t need to search the bmu, taking the min of the distances would already solve our problem.\nIn summary, I think we already have all elements. What do you think?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, your understanding is perfect! You’ve made a very astute observation about reusing the distance calculation and just needing the minimum value rather than its position.\nFor each input x, we: 1. Calculate distances to all nodes (using our dist_fn) 2. Take the minimum distance (don’t need argmin, just min) 3. Average these minimum distances across all inputs\nWould you like to try implementing this as a function? We can use numpy’s vectorized operations to make it efficient. Would you like to try it yourself first, or would you like some guidance?\n\n\n\nqe_err = lambda X,ws: np.array([dist_fn(x, ws).min() for x in X]).mean()\nqe_err(X,ws)\n\n0.14465875369726378\n\n\n\nn_samples = len(X)\ngrid_sz = (n_nodes(n_samples),n_nodes(n_samples))\nws = np.random.randn(*grid_sz, X.shape[-1])\n\nqe_errs = []\nn_epochs = 20\nfor epoch in range(n_epochs):\n    X_ = np.random.permutation(X)\n    for x in X:\n        kernelf_fn = partial(gaussian_fn, sigma=1)\n        ws = update(x, ws, dist_fn, kernel_fn, lr=0.1)\n    qe_errs.append(qe_err(X, ws))\n\n\nplt.figure(figsize=(3, 2))\nplt.plot(range(1, n_epochs+1), qe_errs, lw=1)\nplt.grid(True, alpha=0.3)\nplt.xlabel('Epoch')\nplt.ylabel('Quantization Error')\nplt.title('SOM Training Progress')\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nII.5 Topographic Error (TE)\nAI Prompt\nLet me give you my understanding of the Topographic Error metric. For each sample, - we take is best matching unit (bmu1) and its second best matching unit (bmu2) - if bmu2 is not adjacent (left, right, bottom, up, bottom right, …) to bmu1 we count it as one error\nTE is simply the percentage of the number of such errors over the total number of training samples. Is my understanding correct?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, your understanding of Topographic Error is exactly right! Let’s break down the key points:\n\nFor each input sample:\n\nFind BMU (1st best)\nFind second BMU (2nd best)\nCheck if they’re adjacent using our neighbor definition\nCount as error if not adjacent\n\nFinal TE = (number of errors) / (total samples)\n\nWe already have most pieces: - Distance calculation - BMU finding - Neighbor definition (from U-Matrix implementation)\nWould you like to create a function to: 1. Find the second-best BMU (we’ll need to modify our existing BMU code), or 2. Check if two positions are adjacent (we can use our nbr_offsets from earlier)\nWhich part would you like to tackle first?\n\n\nAI Prompt\nHow could I find the index of the two closest units/element in a SOM/array? I could possibly identify the bmu using the function already available, reassign the value of this bmu to np.inf on a copy of the som and take the bmu again to get the second one. What do you think? It is likely we can do it in a more straightforward way, don’t you think?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nAh yes, there’s a more elegant way! We can use np.argpartition() which is specifically designed to find the k smallest (or largest) elements in an array. It’s more efficient than your suggested approach since:\n\nIt doesn’t require making a copy\nIt only partially sorts the array (just enough to find the k smallest values)\nIt’s a single operation\n\nWould you like to explore how to use np.argpartition() to find the indices of the two smallest distances? We can then use np.unravel_index() like we did before to convert these to grid coordinates.\nWould you like to try this approach?\n\n\nAI Prompt\nCan you explain how to retrieve the two smallest value in a 2D numpy array using np.argpartition?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nLet’s break this down with a simple example:\n# Create a sample 2D array\narr = np.array([[5, 2, 3],\n                [1, 7, 4],\n                [6, 8, 9]])\n\n# Get indices of 2 smallest values using np.argpartition\n# We first flatten the array, then find indices of 2 smallest values\nflat_indices = np.argpartition(arr.flatten(), 2)[:2]\n\n# Convert flat indices back to 2D coordinates using unravel_index\nindices_2d = np.unravel_index(flat_indices, arr.shape)\nWould you like to try this with a small example to see how it works? We can then adapt it for our SOM distances.\n\n\n\n# Create a sample 2D array\narr = np.array([[5, 2, 3],\n                [1, 7, 4],\n                [6, 8, 9]])\n\n# Get indices of 2 smallest values using np.argpartition\n# We first flatten the array, then find indices of 2 smallest values\nflat_indices = np.argpartition(arr.flatten(), 2)[:2]\nprint(f'flat indices: {flat_indices}')\n\n# Convert flat indices back to 2D coordinates using unravel_index\nrows_idx, cols_idx = np.unravel_index(flat_indices, arr.shape)\nlist(zip(rows_idx, cols_idx))\n\nflat indices: [3 1]\n\n\n[(1, 0), (0, 1)]\n\n\n\nx = np.array([\n    [[1], [3], [1]],\n    [[11], [4], [2]],\n    [[7], [8], [5]]])\n\ndist_fn(np.array(3.9), x)\n\narray([[2.9, 0.9, 2.9],\n       [7.1, 0.1, 1.9],\n       [3.1, 4.1, 1.1]])\n\n\n\narr = dist_fn(np.array(3.9), x)\nflat_indices = np.argpartition(arr.flatten(), 2)[:2]\nrows_idx, cols_idx = np.unravel_index(flat_indices, arr.shape)\nlist(zip(rows_idx, cols_idx))\n\n[(1, 1), (0, 1)]\n\n\nActually by checking directly the difference of rows and cols indices returned for the two closest elements we can already check if they are adjacent or not (if any of the difference of the two &gt; 1).\n\narr = dist_fn(np.array(3.9), x)\nflat_indices = np.argpartition(arr.flatten(), 2)[:2]\nindices = np.unravel_index(flat_indices, arr.shape)\nindices\n\n(array([1, 0]), array([1, 1]))\n\n\n\nany([np.abs(x-y)&gt; 1 for x,y in indices])\n\nFalse\n\n\nOk I think we have everything to implement the TE error.\n\nn_errs = 0\nfor x in X:\n    arr = dist_fn(x, ws)\n    flat_indices = np.argpartition(arr.flatten(), 2)[:2]\n    indices = np.unravel_index(flat_indices, arr.shape)\n    if any([np.abs(x-y)&gt; 1 for x,y in indices]): n_errs+=1\nn_errs\n\n38\n\n\n\ndef te_err(X, ws, dist_fn=dist_fn):\n    n_errs = 0\n    for x in X:\n        arr = dist_fn(x, ws)\n        flat_indices = np.argpartition(arr.flatten(), 2)[:2]\n        indices = np.unravel_index(flat_indices, arr.shape)\n        if any([np.abs(x-y)&gt; 1 for x,y in indices]): n_errs+=1\n    return 100*n_errs / len(X)\n\nte_err(X, ws)\n\n3.8\n\n\n\nn_samples = len(X)\ngrid_sz = (n_nodes(n_samples),n_nodes(n_samples))\nws = np.random.randn(*grid_sz, X.shape[-1])\n\nte_errs = []\nn_epochs = 20\nfor epoch in range(n_epochs):\n    X_ = np.random.permutation(X)\n    for x in X:\n        kernelf_fn = partial(gaussian_fn, sigma=1)\n        ws = update(x, ws, dist_fn, kernel_fn, lr=0.1)\n    te_errs.append(te_err(X, ws))\n\n\nplt.figure(figsize=(3, 2))\nplt.plot(range(1, n_epochs+1), te_errs, lw=1)\nplt.grid(True, alpha=0.3)\nplt.xlabel('Epoch')\nplt.ylabel('Topographic Error')\nplt.title('SOM Training Progress')\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nII.6 LR and σ schedulers\nAI Prompt\nWe want a scheduler that given current step (epoch?) will decay both the learning rate and sigma for instance. Now I have a question. What do you think, should I make it flexible enough so that we could potentially decay them even before the end of an epoch?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nThat’s a great question! Yes, making the scheduler flexible enough to handle both epoch-level and sample-level updates would be more versatile, because:\n\nDifferent SOM implementations might need:\n\nEpoch-level decay (simpler, more common)\nMini-batch decay\nSample-level decay (finest granularity)\n\nSome papers suggest that fine-grained decay can be beneficial for:\n\nBetter convergence\nMore precise neighborhood adaptation\nHandling streaming data\n\n\nWould you like to design a scheduler interface that can handle both cases? We could: 1. Make it step-based rather than epoch-based 2. Let the user define what constitutes a “step” 3. Allow different decay functions\nWould you like to explore any of these aspects first?\n\n\nAI Prompt\nLetting users define what constitues a “step” (e.g every n samples) sounds more flexible I think. Let’s implement it.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nGood choice! Let’s design a flexible scheduler. We’ll need to:\n\nTrack:\n\nCurrent step number\nInitial value (lr or sigma)\nDecay function\n\nAllow users to:\n\nDefine custom decay functions\nSpecify when to step (sample, batch, epoch)\n\n\nWould you like to start with implementing a basic scheduler class or first explore some common decay functions?\nFor decay functions, we could implement common ones like: - Linear decay - Exponential decay - Power decay (polynomial)\nWhich would you prefer to tackle first?\n\n\nAI Prompt\nI step_sz means the every number of samples requires before updating a value. How to name the total number of samples*number of epochs where we reach the end of the decay?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nIn scheduling contexts, this is often called the “total_steps” or “max_steps” - it represents the total number of update opportunities over the entire training process.\nSo if we have: - n_samples = 1000 - n_epochs = 20 - step_size = 10 (update every 10 samples)\nThen:\ntotal_steps = (n_samples * n_epochs) // step_size\nWould you like to use one of these names, or do you have another preference for what to call this parameter? We could also call it “decay_steps” or “schedule_length” if you think that would be clearer.\n\n\n\n3000//step_sz\n\n0\n\n\n\ndef exp_sched(start_val, end_val, i, n_steps):\n    decay = -np.log(end_val/start_val)/n_steps\n    return start_val * np.exp(-decay * i)\n\nstep_sz = 5000\nn_samples = 10_000 \nn_epochs = 10\nn_steps = n_epochs*n_samples//step_sz\nstart_v, end_v = 10, 1\n\nstep_idx = 0\nv = start_v\nvs = []\nsteps = []\nfor i in range(n_epochs):\n    for j in range(n_samples):\n        total_samples = i*n_samples + j\n        if total_samples % step_sz == 0:\n            v = exp_sched(start_v, end_v, step_idx, n_steps)\n            vs.append(v)\n            steps.append(step_idx)\n            step_idx+=1\n\n\nplt.figure(figsize=(2, 1))\nplt.plot(steps, vs, lw=1)\nplt.grid(True)\nplt.xlabel('Sample index')\nplt.ylabel('Value')\nplt.title('Exponential Decay Schedule')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom fastcore.all import *\n\n\nclass Scheduler:\n    def __init__(self, start_val, end_val, step_size, \n                 n_samples, n_epochs, decay_fn=exp_sched):\n        store_attr()\n        self.current_step = 0\n        self.current_value = start_val\n        self.total_steps = (n_samples * n_epochs) // step_size\n    \n    def step(self, total_samples):\n        if total_samples % self.step_size == 0:\n            self.current_value = self.decay_fn(\n                self.start_val, self.end_val, \n                self.current_step, self.total_steps\n            )\n            self.current_step += 1\n        return self.current_value\n\n\n\nII.7 Advanced training loop with schedulers\n\nn_samples = len(X)\ngrid_sz = (n_nodes(n_samples),n_nodes(n_samples))\nws = np.random.randn(*grid_sz, X.shape[-1])\n\nstep_size=100\nlr_scheduler = Scheduler(start_val=1, end_val=0.01, step_size=step_size, \n                        n_samples=len(X), n_epochs=n_epochs)\nsigma_scheduler = Scheduler(start_val=6.0, end_val=1., step_size=step_size, \n                          n_samples=len(X), n_epochs=n_epochs)\n\nn_epochs = 20\n# Training loop\nfor epoch in range(n_epochs):\n    X_ = np.random.permutation(X)\n    for i, x in enumerate(X_):\n        total_samples = epoch * len(X) + i\n        \n        # Get current lr and sigma values\n        lr = lr_scheduler.step(total_samples)\n        sigma = sigma_scheduler.step(total_samples)\n        \n        # Update weights using current lr and sigma\n        kernel_fn = partial(gaussian_fn, sigma=sigma)\n        ws = update(x, ws, dist_fn, kernel_fn, lr=lr)\n\n\ndef fit(X, ws, lr_scheduler, sigma_scheduler, n_epochs=20, shuffle=True):\n    qe_errs = []\n    te_errs = []\n    for epoch in range(n_epochs):\n        X_ = np.random.permutation(X) if shuffle else X.copy()\n        for i, x in enumerate(X_):\n            total_samples = epoch * len(X) + i\n            lr = lr_scheduler.step(total_samples)\n            sigma = sigma_scheduler.step(total_samples)\n            kernel_fn = partial(gaussian_fn, sigma=sigma)\n            ws = update(x, ws, dist_fn, kernel_fn, lr=lr)\n        qe, te = qe_err(X,ws), te_err(X,ws)\n        qe_errs.append(qe)\n        te_errs.append(te)\n        print(f'Epoch: {epoch+1} | QE: {qe_err(X,ws)}, TE: {te_err(X,ws)}')\n    return ws, qe_errs, te_errs\n\n\nn_samples = len(X)\ngrid_sz = (n_nodes(n_samples),n_nodes(n_samples))\nws = np.random.randn(*grid_sz, X.shape[-1])\n\nstep_size=100\nlr_scheduler = Scheduler(start_val=1, end_val=0.01, step_size=step_size, \n                        n_samples=len(X), n_epochs=n_epochs)\nsigma_scheduler = Scheduler(start_val=6.0, end_val=1., step_size=step_size, \n                          n_samples=len(X), n_epochs=n_epochs)\n\nws, qe_errs, te_errs = fit(X, ws, lr_scheduler, sigma_scheduler, n_epochs=20)\n\nEpoch: 1 | QE: 0.7361545362516652, TE: 0.1\nEpoch: 2 | QE: 0.5148950211961353, TE: 1.4\nEpoch: 3 | QE: 0.4161479264406785, TE: 2.5\nEpoch: 4 | QE: 0.3261032895452769, TE: 0.3\nEpoch: 5 | QE: 0.4344722303659532, TE: 0.6\nEpoch: 6 | QE: 0.4660129942532872, TE: 0.1\nEpoch: 7 | QE: 0.3492315992581065, TE: 0.6\nEpoch: 8 | QE: 0.30374238796782127, TE: 1.3\nEpoch: 9 | QE: 0.31955520142421034, TE: 0.4\nEpoch: 10 | QE: 0.26528420358326743, TE: 0.3\nEpoch: 11 | QE: 0.23678200850531003, TE: 0.8\nEpoch: 12 | QE: 0.21944164206845745, TE: 0.6\nEpoch: 13 | QE: 0.20784349249994324, TE: 0.5\nEpoch: 14 | QE: 0.20141528673718959, TE: 1.2\nEpoch: 15 | QE: 0.18861138082733617, TE: 0.9\nEpoch: 16 | QE: 0.17765457467386436, TE: 1.5\nEpoch: 17 | QE: 0.17077969894350056, TE: 1.1\nEpoch: 18 | QE: 0.16341102935415364, TE: 1.5\nEpoch: 19 | QE: 0.15816356896585257, TE: 1.3\nEpoch: 20 | QE: 0.154156360812519, TE: 0.7\n\n\n\nplot_umatrix(ws)\n\n\n\n\n\n\n\n\nAI Prompt\nI am wondering how to best choose the initial and end learning rate and sigma. Is there any standard methodology other than grid search? Any thumb of rules I must be aware of?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, there are some common guidelines for SOM hyperparameters:\n\nLearning Rate (lr):\n\nStart: Usually between 0.1 and 1.0\nEnd: Small but non-zero (0.01 or even smaller)\nRule of thumb: Higher initial lr for larger datasets/maps\n\nSigma (neighborhood radius):\n\nStart: Usually max(grid_width, grid_height)/2\nEnd: Should cover about one unit (0.5-1.0)\nRule of thumb: Larger initial sigma helps global ordering\n\nGeneral principles:\n\nTraining has two phases:\n\nOrdering phase: High lr and sigma for global organization\nFine-tuning phase: Low lr and sigma for local adjustments\n\nTraining length should be at least 500 times number of nodes\n\n\nWould you like to try adjusting your parameters based on these guidelines?\n\n\n\n\nII.8 Revised plan\nAI Prompt\nNo that’s ok for now, thanks a lot! Now I think we need once more time to revise the plan as we are making very good progress and focus on the remaining steps. As a reminder, here below the previous plan: You make excellent points! Yes, we should revise the plan to better integrate visualization and metrics with the training loop, since they’re crucial for understanding how the SOM evolves. Here’s a suggested revision:\n\nCore SOM Components (DONE)\n\n✓ Initialize weight grid\n✓ Distance metrics\n✓ BMU function\n✓ Neighborhood function\n✓ Weight update rule\n\nExtended Training Components\n\nTraining loop structure - DONE\nU-Matrix visualization (moved up from 4) - DONE\nBasic quality metrics (moved up from 3) - DONE\nLearning rate scheduler - DONE\nRadius scheduler - DONE\nTraining progress visualization - DONE\n\nAdditional Quality Metrics\n\nQuantization error - DONE\nTopographic error - DONE\nCustom metrics interface\n\nAdditional Visualizations\n\nComponent planes\nCustom visualization options\n\nRefactoring\n\nClass structure\nFlexible interfaces\nDocumentation\n\n\nI have further specified which steps were already completed! You evoked additional visualization techniques (on top of the u-matrix) and possible additional metrics. Last the refactoring and documentation phases remains highligh important as final steps. However there is one important aspects we have not addressed that we should address next which is the initialization of the SOM/weights. Now we are doing it randomly, I think we can use PCA also. I would be interested to understand it in further details and implement it.\nCan you advise and propose an update plan? Important: Consider the numbering of each steps already used so that the new plan can be appended to it consistently.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nYes, you’re right! The PCA initialization is an important addition. Here’s the updated plan, maintaining consistent numbering and adding the initialization as step 6 before refactoring:\n\nWeights Initialization Methods\n\n\nRandom (current - DONE)\nPCA-based initialization\nComparison of initialization impacts\n\n\nAdditional Quality Metrics & Visualization\n\n\nComponent planes\nAdditional custom metrics interface\nCustom visualization options\n\nV. Refactoring & Documentation - Class structure - Flexible interfaces - Comprehensive documentation - Usage examples\nWould you like to start exploring the PCA initialization approach? I can explain how PCA can help initialize the SOM weights more effectively than random initialization.",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#iii.-weights-initialization-methods",
    "href": "workflow/how-was-it-created.html#iii.-weights-initialization-methods",
    "title": "How was it created?",
    "section": "III. WEIGHTS INITIALIZATION METHODS",
    "text": "III. WEIGHTS INITIALIZATION METHODS\nAI Prompt\nCan you explain what’s the idea of using PCA to initialize SOM weights?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nThe idea behind PCA initialization for SOM weights is quite clever:\n\nMain concept:\n\nInstead of random initialization, we want initial weights that already reflect the data’s structure\nPCA finds the principal directions of variation in your data\nWe can use these directions to create a more informed initial grid\n\nThe process typically works by:\n\nFinding the two largest principal components of your data\nUsing these to create a linear interpolation grid\nThis grid becomes your initial weights\n\nBenefits:\n\nFaster convergence (weights start closer to final configuration)\nMore stable training\nBetter preservation of data topology\n\n\nWould you like me to explain more about how this works in practice, or would you prefer to start implementing it?\n\n\nAI Prompt\nYes I know PCA but your statement “Using these to create a linear interpolation grid” is a bit unclear to me. Please further elaborate.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nAh, let me clarify the linear interpolation part:\nLet’s say we have a 4x4 SOM grid and our data is 3-dimensional. After PCA:\n\nWe get two principal components (PC1 and PC2)\n\nThese define a 2D plane where data varies most\n\nThe “linear interpolation grid” means:\n\nAlong rows: We interpolate values from -1 to 1 using PC1 (4 points)\nAlong columns: We interpolate values from -1 to 1 using PC2 (4 points)\nEach grid point becomes: (αPC1 + βPC2)\nWhere α and β are the interpolated values\n\n\nSo each weight vector is a linear combination of PC1 and PC2, creating a regular grid that spans the main directions of variation in your data.\nWould you like to see this process with a small example using your dataset?\n\n\nAI Prompt\nThanks it’s a bit clearer. Let me try to reformulate it, in the context of a highly dimensional dataset (which is the primary target of SOM), we take the two largest principal components (PCs) and generate the initial weights of the grid in the span of those two PCs.\nI have two remarks: - in the situation where our input dataset is 2D, there would be no added value as we could have equally taken initial weights in the span of the initial basis (randomly) - don’t you think that would be also important to consider the eigen values (% of variance explained by each PCs) to generate those initial SOM weights? Do you see my point?\nWhat do you think?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nExcellent observations! Let me address both points:\n\n2D data case:\n\n✓ You’re absolutely right! PCA initialization would be less beneficial\nThe benefit really shows in higher dimensions where random initialization might miss important data structure\n\nEigenvalues consideration:\n\n✓ Very insightful point! Yes, the variance explained by each PC is important\nWe could use the eigenvalues to:\n\nScale the grid points according to the relative importance of each PC\nMake the grid more stretched along PC1 if it explains much more variance than PC2\nThis would better reflect the actual data distribution\n\n\n\nWould you like to modify the initialization approach to incorporate the eigenvalues? We could scale the α and β coefficients by the square root of their respective eigenvalues to reflect the relative importance of each direction.\n\n\nAI Prompt\nGreat!Let’s implement it but let me try first.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nPerfect! Go ahead and try implementing it yourself. If you get stuck or want to discuss your implementation, I’m here to help.\nRemember you’ll need to: 1. Perform PCA on your data 2. Get the first two PCs and their eigenvalues 3. Create the interpolation grid with eigenvalue scaling\nLet me know when you want to discuss your implementation or if you need any clarification!\n\n\nTo assess the added value of PCA initialization we should use a higher dimentionsal toy dataset. We choose the MNIST dataset for that purpose as provided by scikitlearn.\n\nfrom sklearn.datasets import load_digits\n\nX, y = load_digits(return_X_y=True)\nX.shape, y.shape\n\n((1797, 64), (1797,))\n\n\n\n# Using column-wise centering to keep pixels correlation\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\nX_norm[:3,:3]\n\narray([[-0.28710938, -0.28710938,  0.02539062],\n       [-0.30566406, -0.30566406, -0.30566406],\n       [-0.3359375 , -0.3359375 , -0.3359375 ]])\n\n\n\nplt.figure(figsize=(1, 1))  \nplt.axis('off')\nplt.imshow(X_norm[16].reshape(8,8), cmap='gray')\nplt.tight_layout(pad=0)\nplt.show()",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#iii.1-random-initialization",
    "href": "workflow/how-was-it-created.html#iii.1-random-initialization",
    "title": "How was it created?",
    "section": "III.1 Random initialization",
    "text": "III.1 Random initialization\n\n#n_samples = len(X)\n#grid_sz = (n_nodes(n_samples),n_nodes(n_samples))\ngrid_sz = (20,20)\nws = np.random.randn(*grid_sz, X.shape[-1])\n\nstep_size=200\nlr_scheduler = Scheduler(start_val=1, end_val=0.01, step_size=step_size, \n                         n_samples=len(X), n_epochs=n_epochs)\nsigma_scheduler = Scheduler(start_val=10.0, end_val=1., step_size=step_size, \n                            n_samples=len(X), n_epochs=n_epochs)\n\nws, qe_errs, te_errs = fit(X_norm, ws, lr_scheduler, sigma_scheduler, n_epochs=20)\n\nEpoch: 1 | QE: 2.0704569004526077, TE: 1.613800779076238\nEpoch: 2 | QE: 1.9993114714766416, TE: 2.782415136338342\nEpoch: 3 | QE: 1.861177046446639, TE: 0.8903728436282693\nEpoch: 4 | QE: 1.9219833266979651, TE: 2.1702838063439067\nEpoch: 5 | QE: 1.8149792250549173, TE: 1.947690595436839\nEpoch: 6 | QE: 1.7232480060982525, TE: 0.5564830272676683\nEpoch: 7 | QE: 1.6416867945969185, TE: 0.8347245409015025\nEpoch: 8 | QE: 1.6012357873004686, TE: 0.8347245409015025\nEpoch: 9 | QE: 1.525608040533907, TE: 0.38953811908736785\nEpoch: 10 | QE: 1.4982022948153044, TE: 0.11129660545353366\nEpoch: 11 | QE: 1.437747418705183, TE: 0.7790762381747357\nEpoch: 12 | QE: 1.3905844080513237, TE: 0.6121313299944352\nEpoch: 13 | QE: 1.3560227127148223, TE: 0.667779632721202\nEpoch: 14 | QE: 1.3173744703746464, TE: 0.8347245409015025\nEpoch: 15 | QE: 1.2798663316734378, TE: 0.7234279354479688\nEpoch: 16 | QE: 1.2483547543469942, TE: 0.5008347245409015\nEpoch: 17 | QE: 1.219034936826061, TE: 0.44518642181413465\nEpoch: 18 | QE: 1.1926493832743006, TE: 0.44518642181413465\nEpoch: 19 | QE: 1.1704315350038619, TE: 0.6121313299944352\nEpoch: 20 | QE: 1.1514711948834122, TE: 0.8903728436282693\n\n\n\nplot_umatrix(ws)\n\n\n\n\n\n\n\n\n\nIII.2 PCA initialization\n\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\npca.fit(X_norm)\nprint(pca.explained_variance_ratio_)\nprint(pca.singular_values_)\n\n[0.15122797 0.13826949]\n[35.43643386 33.88419201]\n\n\n\npca.components_.shape\n\n(2, 64)\n\n\n\nnp.linspace(-1,1,num=10)\n\narray([-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n        0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ])\n\n\n\n# -1*e1*v1 + -1*e2*v2\n# -0.9*e1*v1 + -0.9*e2*v2\n\nAI Prompt\nOnce I have the 2 highest eigen values and vectors, how do I create a nxn matrix to be used as SOM based on this?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nFor a n×n SOM grid, here’s how to create the PCA-initialized weights:\n\nCreate two sets of coefficients:\n\nalpha = np.linspace(-1, 1, n)  # for PC1\nbeta = np.linspace(-1, 1, n)   # for PC2\n\nScale them by square root of eigenvalues:\n\nalpha *= np.sqrt(pca.explained_variance_[0])\nbeta *= np.sqrt(pca.explained_variance_[1])\n\nCreate the grid using outer products:\n\n# Create meshgrid\nalpha_grid, beta_grid = np.meshgrid(alpha, beta)\n\n# Initialize weights array\nweights = np.zeros((n, n, X.shape[1]))  # shape: (n, n, 64) for MNIST\n\n# Each weight is a linear combination of PC1 and PC2\nweights = (alpha_grid[..., np.newaxis] * pca.components_[0] + \n          beta_grid[..., np.newaxis] * pca.components_[1])\nWould you like to try implementing this approach?\n\n\n\ngrid_sz = (20,20)\nn = grid_sz[0]\nalpha = np.linspace(-1, 1, n)  # for PC1\nbeta = np.linspace(-1, 1, n)   # for PC2\n\n\nalpha *= np.sqrt(pca.explained_variance_[0])\nbeta *= np.sqrt(pca.explained_variance_[1])\n\n\nalpha_grid, beta_grid = np.meshgrid(alpha, beta)\n\n\nws = np.zeros((n, n, X.shape[1]))\n\n\nws = (alpha_grid[..., np.newaxis] * pca.components_[0] + \n          beta_grid[..., np.newaxis] * pca.components_[1])\nws.shape\n\n(20, 20, 64)\n\n\n\nstep_size=200\nlr_scheduler = Scheduler(start_val=1, end_val=0.01, step_size=step_size, \n                         n_samples=len(X), n_epochs=n_epochs)\nsigma_scheduler = Scheduler(start_val=10.0, end_val=1., step_size=step_size, \n                            n_samples=len(X), n_epochs=n_epochs)\n\nws, qe_errs, te_errs = fit(X_norm, ws, lr_scheduler, sigma_scheduler, n_epochs=20)\n\nEpoch: 1 | QE: 2.021117062983796, TE: 2.949360044518642\nEpoch: 2 | QE: 2.0374532407086186, TE: 3.728436282693378\nEpoch: 3 | QE: 1.9381056000802876, TE: 1.1686143572621035\nEpoch: 4 | QE: 1.8750135481900163, TE: 3.394546466332777\nEpoch: 5 | QE: 1.7731177749486253, TE: 0.9460211463550362\nEpoch: 6 | QE: 1.7381528690875534, TE: 1.1129660545353366\nEpoch: 7 | QE: 1.6576526895942232, TE: 1.335559265442404\nEpoch: 8 | QE: 1.585401407283374, TE: 1.279910962715637\nEpoch: 9 | QE: 1.564939121993558, TE: 0.9460211463550362\nEpoch: 10 | QE: 1.4887308931209031, TE: 0.8347245409015025\nEpoch: 11 | QE: 1.4567525145876061, TE: 0.8347245409015025\nEpoch: 12 | QE: 1.3981773691503705, TE: 0.667779632721202\nEpoch: 13 | QE: 1.3556213938081516, TE: 0.667779632721202\nEpoch: 14 | QE: 1.317842103259422, TE: 0.7790762381747357\nEpoch: 15 | QE: 1.2812507568473976, TE: 0.5008347245409015\nEpoch: 16 | QE: 1.2470507719706745, TE: 0.5564830272676683\nEpoch: 17 | QE: 1.2189855689098217, TE: 0.5564830272676683\nEpoch: 18 | QE: 1.1935169201963478, TE: 0.5008347245409015\nEpoch: 19 | QE: 1.1719132431346526, TE: 0.6121313299944352\nEpoch: 20 | QE: 1.1539758415894774, TE: 0.8347245409015025\n\n\n\nplot_umatrix(ws)\n\n\n\n\n\n\n\n\nAI Prompt\nThe effect of PCA initialization is not probative above. How could I see the added value?\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nTo better demonstrate the value of PCA initialization, we could:\n\nCompare convergence speed:\n\nRun both initializations multiple times\nPlot learning curves (QE vs epochs) on the same graph\nStart with fewer epochs to see early convergence\n\nUse a more complex dataset:\n\nMNIST digits at higher resolution\nOr a dataset with more pronounced principal components\nCurrently we’re using 8x8 digits which might be too simple\n\nVisualize initial state:\n\nShow U-Matrix right after initialization (before training)\nCompare random vs PCA initialization structures\n\nAdjust hyperparameters:\n\nDifferent learning rates\nDifferent grid sizes\nDifferent sigma values\n\n\nWhich approach would you like to try first to better demonstrate the difference between random and PCA initialization?\n\n\nAI Prompt\nThanks, very useful! That’s fine for now I will perform this thorough assessment later.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nAlright! We’ve covered PCA initialization and have some good ideas for evaluating its effectiveness later.\nWould you like to move on to the next part of our plan? We could look at: 1. Component planes visualization 2. Additional quality metrics 3. Start the refactoring phase\nWhich would you prefer to tackle next?",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#iv.-additional-visualizations",
    "href": "workflow/how-was-it-created.html#iv.-additional-visualizations",
    "title": "How was it created?",
    "section": "IV. ADDITIONAL VISUALIZATIONS",
    "text": "IV. ADDITIONAL VISUALIZATIONS\nAI Prompt\nExplain me the concept of “Component planes visualization” in the contexte of the MNIST dataset for instance.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nIn the context of MNIST, component planes visualization is particularly interesting:\n\nBasic concept:\n\nEach weight vector (node) has 64 components (8x8 pixels)\nA component plane shows how ONE of these 64 components varies across the SOM grid\nWe get 64 different “heatmaps”, one for each pixel position\n\nFor MNIST specifically:\n\nEach component plane shows how a specific pixel varies across the map\nBright areas = high pixel values in that position\nDark areas = low pixel values in that position\nThis reveals which regions of the SOM activate specific parts of the digits\n\nInterpretation:\n\nSimilar patterns across component planes suggest correlated pixels\nSome planes might show clear structures (e.g., strong activation in middle pixels for digit “1”)\nHelps understand how the SOM has organized digit features\n\n\nWould you like to visualize some component planes for our trained MNIST SOM to see this in practice?\n\n\nAI Prompt\nOk I see, I will implement it later, let’s focus on the refactoring and the documentation now.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nSure! For refactoring, we should create a well-structured class that encapsulates all the functionality we’ve built. Here’s what we could consider:\n\nCore SOM Class structure:\n\nInitialization (random/PCA)\nTraining methods\nVisualization methods\nQuality metrics\nFlexible interfaces for schedulers\n\nDocumentation needs:\n\nClear docstrings\nUsage examples\nParameter descriptions\nReferences to literature\n\n\nWould you like to start with: 1. Designing the class interface 2. Writing the documentation structure 3. Organizing the methods we’ve created\nWhich aspect would you prefer to tackle first?",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#v.-refactoring",
    "href": "workflow/how-was-it-created.html#v.-refactoring",
    "title": "How was it created?",
    "section": "V. REFACTORING",
    "text": "V. REFACTORING\nAI Prompt\nPlease design a class interface embedding all components implemented above. Make sure to: - use nbdev-like documentation and docstrings - use fastai coding style\n\n\n\n\n\n\nTip\n\n\n\nI’ll design a class interface following nbdev and fastai style. Let’s start with the core class structure:\nclass SOM:\n    def __init__(self, grid_sz:tuple, # Size of the SOM grid (rows, cols)\n                 input_dim:int,        # Dimension of input data\n                 init:str='random',    # Initialization method: 'random' or 'pca'\n                 dist_fn=np.linalg.norm # Distance metric function\n                ):\n        \"Initialize a Self-Organizing Map with given grid size and input dimension\"\n        \n    def fit(self, X:np.ndarray,           # Training data\n            n_epochs:int=20,              # Number of training epochs\n            lr_scheduler:Scheduler=None,   # Learning rate scheduler\n            sigma_scheduler:Scheduler=None, # Neighborhood radius scheduler\n            shuffle:bool=True,             # Shuffle data each epoch\n            verbose:bool=True              # Print training progress\n           )-&gt;tuple:                       # Returns (weights, qe_errors, te_errors)\n        \"Train the SOM on input data X\"\n        \n    def transform(self, X:np.ndarray # Input data to transform\n                )-&gt;np.ndarray:       # Returns BMU coordinates for each input\n        \"Find Best Matching Unit (BMU) for each input vector\"\n        \n    @property\n    def umatrix(self)-&gt;np.ndarray:  # Returns U-Matrix of current weights\n        \"Calculate and return the U-Matrix\"\n        \n    def quantization_error(self, X:np.ndarray # Input data\n                         )-&gt;float:            # Returns QE value\n        \"Calculate quantization error for input data\"\n        \n    def topographic_error(self, X:np.ndarray # Input data\n                        )-&gt;float:            # Returns TE value\n        \"Calculate topographic error for input data\"\nWould you like me to: 1. Add more methods 2. Elaborate on any particular method 3. Add more documentation details 4. Show how the existing functions would fit into this structure\nWhat would be most helpful?\n\n\nAI Prompt\nThe interface looks fine, please feed it with the implementations\n\n\n\n\n\n\nTip\n\n\n\nI’ll help you implement the class step by step. Let’s start with the core structure and basic methods:\nclass SOM:\n    def __init__(self, grid_sz:tuple, input_dim:int, init:str='random', dist_fn=np.linalg.norm):\n        \"Initialize a Self-Organizing Map with given grid size and input dimension\"\n        store_attr()\n        self.weights = self._initialize_weights(init)\n        \n    def _initialize_weights(self, method:str)-&gt;np.ndarray:\n        \"Initialize weights using either random or PCA initialization\"\n        if method == 'random':\n            return np.random.randn(*self.grid_sz, self.input_dim)\n        elif method == 'pca':\n            # We'll implement PCA initialization\n            raise NotImplementedError(\"PCA initialization to be implemented\")\nWould you like me to continue with implementing more methods? We can do this incrementally, testing each part as we go. Which method would you like to implement next?\n\nPCA initialization\nCore training loop (fit)\nTransform method\nError metrics\n\nLet me know which you’d prefer to tackle first!\n\n\nAI Prompt\nNext implement, PCA initialization.\n\n\n\n\n\n\nTip\n\n\n\nI’ll add the PCA initialization to our SOM class. We’ll need to modify the _initialize_weights method and add a helper method for PCA:\nfrom sklearn.decomposition import PCA\n\nclass SOM:\n    def __init__(self, grid_sz:tuple, input_dim:int, init:str='random', dist_fn=np.linalg.norm):\n        \"Initialize a Self-Organizing Map with given grid size and input dimension\"\n        store_attr()\n        self.weights = None  # Will be initialized when fitting\n        \n    def _initialize_weights_pca(self, X:np.ndarray)-&gt;np.ndarray:\n        \"Initialize weights using PCA of the input data\"\n        pca = PCA(n_components=2)\n        pca.fit(X)\n        \n        # Create grid coordinates and scale by eigenvalues\n        n = self.grid_sz[0]\n        alpha = np.linspace(-1, 1, n) * np.sqrt(pca.explained_variance_[0])\n        beta = np.linspace(-1, 1, n) * np.sqrt(pca.explained_variance_[1])\n        \n        # Create the grid\n        alpha_grid, beta_grid = np.meshgrid(alpha, beta)\n        \n        # Initialize weights as linear combination of first two PCs\n        return (alpha_grid[..., np.newaxis] * pca.components_[0] + \n                beta_grid[..., np.newaxis] * pca.components_[1])\n    \n    def _initialize_weights(self, X:np.ndarray=None, method:str='random')-&gt;np.ndarray:\n        \"Initialize weights using either random or PCA initialization\"\n        if method == 'random':\n            return np.random.randn(*self.grid_sz, self.input_dim)\n        elif method == 'pca':\n            if X is None: \n                raise ValueError(\"Data matrix X required for PCA initialization\")\n            return self._initialize_weights_pca(X)\nNote that we’ve modified the initialization to: 1. Accept the input data X when needed for PCA 2. Move PCA logic to a separate method 3. Make weights initialization defer until we have data\nWould you like to implement the next component? We could tackle: 1. Core training loop (fit) 2. Transform method 3. Error metrics\nWhich would you prefer?\n\n\nAI Prompt\nImplement the core training loop\n\n\n\n\n\n\nTip\n\n\n\nI’ll implement the core training loop (fit method) and its supporting functions. We’ll need to include the neighborhood and update logic we developed earlier:\nclass SOM:\n    # ... (previous methods remain the same)\n    \n    def _find_bmu(self, x:np.ndarray)-&gt;tuple:\n        \"Find coordinates of Best Matching Unit for input x\"\n        distances = self.dist_fn(x, self.weights)\n        return np.unravel_index(np.argmin(distances), self.grid_sz)\n    \n    def _grid_distances(self, bmu_pos:tuple)-&gt;np.ndarray:\n        \"Calculate grid distances from BMU position\"\n        rows_idx, cols_idx = np.ogrid[0:self.grid_sz[0], 0:self.grid_sz[1]]\n        return (bmu_pos[0] - rows_idx)**2 + (bmu_pos[1] - cols_idx)**2\n    \n    def _neighborhood_function(self, grid_dist:np.ndarray, sigma:float)-&gt;np.ndarray:\n        \"Calculate neighborhood function values\"\n        return np.exp(-grid_dist/(2*sigma**2))\n    \n    def _update_weights(self, x:np.ndarray, learning_rate:float, sigma:float):\n        \"Update weights for a single input vector\"\n        bmu_pos = self._find_bmu(x)\n        grid_dist = self._grid_distances(bmu_pos)\n        neighborhood = self._neighborhood_function(grid_dist, sigma)\n        self.weights += learning_rate * neighborhood[..., np.newaxis] * (x - self.weights)\n    \n    def fit(self, X:np.ndarray, n_epochs:int=20, \n            lr_scheduler:Scheduler=None, sigma_scheduler:Scheduler=None,\n            shuffle:bool=True, verbose:bool=True)-&gt;tuple:\n        \"Train the SOM on input data X\"\n        # Initialize weights if not already done\n        if self.weights is None:\n            self.weights = self._initialize_weights(X, self.init)\n        \n        # Setup default schedulers if none provided\n        if lr_scheduler is None:\n            lr_scheduler = Scheduler(1.0, 0.01, 100, len(X), n_epochs)\n        if sigma_scheduler is None:\n            sigma_scheduler = Scheduler(max(self.grid_sz)/2, 1.0, 100, len(X), n_epochs)\n        \n        qe_errors, te_errors = [], []\n        for epoch in range(n_epochs):\n            X_ = np.random.permutation(X) if shuffle else X.copy()\n            \n            # Train on each input vector\n            for i, x in enumerate(X_):\n                total_samples = epoch * len(X) + i\n                lr = lr_scheduler.step(total_samples)\n                sigma = sigma_scheduler.step(total_samples)\n                self._update_weights(x, lr, sigma)\n            \n            # Calculate errors\n            qe = self.quantization_error(X)\n            te = self.topographic_error(X)\n            qe_errors.append(qe)\n            te_errors.append(te)\n            \n            if verbose:\n                print(f'Epoch: {epoch+1} | QE: {qe:.4f}, TE: {te:.4f}')\n        \n        return self.weights, qe_errors, te_errors\nWould you like me to: 1. Add the error metrics methods next 2. Add the transform method 3. Explain any part of this implementation in more detail\nWhich would you prefer?\n\n\nAI Prompt\nOk, add the error metrics methods next\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nI’ll add the error metrics methods to our SOM class:\nclass SOM:\n    # ... (previous methods remain the same)\n    \n    def quantization_error(self, X:np.ndarray)-&gt;float:\n        \"Calculate average distance between each input vector and its BMU\"\n        return np.array([\n            self.dist_fn(x, self.weights).min() \n            for x in X\n        ]).mean()\n    \n    def topographic_error(self, X:np.ndarray)-&gt;float:\n        \"Calculate proportion of data vectors where 1st and 2nd BMUs are not adjacent\"\n        def _check_bmu_adjacency(x):\n            # Get indices of two best matching units\n            distances = self.dist_fn(x, self.weights)\n            flat_indices = np.argpartition(distances.flatten(), 2)[:2]\n            indices = np.unravel_index(flat_indices, self.grid_sz)\n            # Check if any coordinate differs by more than 1\n            return any(np.abs(x-y) &gt; 1 for x,y in indices)\n        \n        n_errors = sum(_check_bmu_adjacency(x) for x in X)\n        return 100 * n_errors / len(X)  # Return percentage\nWould you like me to: 1. Add the transform method next 2. Add the U-Matrix visualization 3. Add component planes visualization 4. Something else?\nWhich would you prefer?\n\n\nAI Prompt\nAdd the transform method.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nI’ll add the transform method to find BMU coordinates for new data points:\nclass SOM:\n    # ... (previous methods remain the same)\n    \n    def transform(self, X:np.ndarray)-&gt;np.ndarray:\n        \"Find Best Matching Unit (BMU) coordinates for each input vector\"\n        bmu_coords = np.zeros((len(X), 2), dtype=int)\n        for i, x in enumerate(X):\n            bmu_coords[i] = self._find_bmu(x)\n        return bmu_coords\n    \n    def predict(self, X:np.ndarray)-&gt;np.ndarray:\n        \"Alias for transform method to follow sklearn convention\"\n        return self.transform(X)\nI added both transform and predict methods to follow scikit-learn conventions. The predict method is just an alias for transform.\nWould you like me to: 1. Add the U-Matrix visualization next 2. Add component planes visualization 3. Add any other methods?\nWhich would you prefer?\n\n\nAI Prompt\nNow, implement the U-matrix component.\n\n\n\n\n\n\nTip\n\n\n\nAI Response\nI’ll add the U-Matrix calculation and visualization methods:\nclass SOM:\n    # ... (previous methods remain the same)\n    \n    def _calculate_umatrix(self)-&gt;np.ndarray:\n        \"Calculate U-Matrix values for current weights\"\n        def _neighbor_distances(pos):\n            # Offsets for 8 neighbors\n            nbr_offsets = [\n                (-1,-1), (-1,0), (-1,1),  # top-left, top, top-right\n                (0,-1),          (0,1),   # left, right\n                (1,-1),  (1,0),  (1,1)    # bottom-left, bottom, bottom-right\n            ]\n            \n            distances = []\n            weights = []\n            for dr, dc in nbr_offsets:\n                r, c = pos\n                nbr_r, nbr_c = r+dr, c+dc\n                if (nbr_r &gt;= 0 and nbr_r &lt; self.grid_sz[0] and \n                    nbr_c &gt;= 0 and nbr_c &lt; self.grid_sz[1]):\n                    w = 1/np.sqrt(dr**2 + dc**2)  # weight by distance\n                    weights.append(w)\n                    d = self.dist_fn(self.weights[r,c] - self.weights[nbr_r,nbr_c])\n                    distances.append(d)\n            return np.average(distances, weights=weights)\n        \n        umatrix = np.zeros(self.grid_sz)\n        for i, j in np.ndindex(self.grid_sz):\n            umatrix[i,j] = _neighbor_distances((i,j))\n        return umatrix\n    \n    @property\n    def umatrix(self)-&gt;np.ndarray:\n        \"Return the U-Matrix for current weights\"\n        return self._calculate_umatrix()\n    \n    def plot_umatrix(self, figsize=(8,6), cmap='viridis_r'):\n        \"Plot U-Matrix visualization\"\n        import matplotlib.pyplot as plt\n        \n        plt.figure(figsize=figsize)\n        plt.imshow(self.umatrix, cmap=cmap, interpolation='nearest')\n        plt.colorbar(label='Average distance to neighbors')\n        plt.title('U-Matrix')\n        plt.tight_layout()\n        plt.show()\nI’ve included: 1. Internal calculation method _calculate_umatrix 2. Property getter for easy access to U-Matrix 3. Plotting method with customizable parameters\nWould you like me to: 1. Add component planes visualization next 2. Add any other visualization methods 3. Explain any part of the U-Matrix implementation in more detail?\nWhich would you prefer?\n\n\n\nV.2 Readme.md\nAI Prompt\nLast, I’d like you to generate a README.md file for a package making this SOM implementation available to a wider audience (let’s name this package Teuvo). I’d like it to mention the design philosophy of “SolveIt” also. Use a how to use section using the MNIST dataset for instance.\n\n\n\n\n\n\nTip\n\n\n\nAI Response I’ll create a README.md for the “Teuvo” package (nice reference to Teuvo Kohonen!). I’ll structure it to be clear, informative, and showcase the implementation philosophy:\n# Teuvo: A Pythonic Self-Organizing Map Implementation\n\nA flexible, well-documented implementation of Self-Organizing Maps (SOMs) following the principles of clarity, step-by-step problem solving, and vectorized operations.\n\n## Design Philosophy\n\nThis implementation follows the \"SolveIt\" approach:\n- Break complex problems into manageable steps\n- Prioritize clarity and understanding over premature optimization\n- Document and explain each component thoroughly\n- Use vectorized operations for efficiency\n- Provide flexible interfaces for customization\n\n## Installation\n\n```bash\npip install teuvo\n\nQuick Start\nfrom teuvo import SOM\nimport numpy as np\nfrom sklearn.datasets import load_digits\n\n# Load and normalize MNIST data\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Create and train SOM\nsom = SOM(grid_sz=(20,20), input_dim=64, init='pca')\nsom.fit(X_norm, n_epochs=20)\n\n# Visualize results\nsom.plot_umatrix()\n\n\nFeatures\n\nMultiple initialization methods:\n\nRandom initialization\nPCA-based initialization (for faster convergence)\n\nFlexible training options:\n\nCustomizable learning rate schedules\nAdjustable neighborhood functions\n\nComprehensive quality metrics:\n\nQuantization Error\nTopographic Error\n\nRich visualization tools:\n\nU-Matrix visualization\nComponent planes (coming soon)\n\n\n\n\nDetailed Example: MNIST Digit Classification\nfrom teuvo import SOM\nfrom teuvo.schedulers import Scheduler\nimport numpy as np\nfrom sklearn.datasets import load_digits\nimport matplotlib.pyplot as plt\n\n# Load and preprocess data\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Initialize SOM\nsom = SOM(\n    grid_sz=(20,20),\n    input_dim=64,\n    init='pca'  # Use PCA initialization\n)\n\n# Create custom schedulers\nlr_scheduler = Scheduler(start_val=1.0, end_val=0.01, \n                       step_size=200, n_samples=len(X), n_epochs=20)\nsigma_scheduler = Scheduler(start_val=10.0, end_val=1.0, \n                          step_size=200, n_samples=len(X), n_epochs=20)\n\n# Train\nweights, qe_errors, te_errors = som.fit(\n    X_norm,\n    n_epochs=20,\n    lr_scheduler=lr_scheduler,\n    sigma_scheduler=sigma_scheduler\n)\n\n# Visualize results\nplt.figure(figsize=(12,4))\n\nplt.subplot(121)\nplt.plot(qe_errors)\nplt.title('Quantization Error')\nplt.xlabel('Epoch')\n\nplt.subplot(122)\nsom.plot_umatrix()\n\nplt.tight_layout()\nplt.show()\n\n\nContributing\nWe welcome contributions! Please see our contributing guidelines for details.\n\n\nReferences\n\nKohonen, T. (1982). Self-organized formation of topologically correct feature maps\nKohonen, T. (2013). Essentials of the self-organizing map\nPolya, G. (1945). How to Solve It\n\n\n\nLicense\nMIT\n\n\nAcknowledgments\nNamed in honor of Teuvo Kohonen, who introduced the Self-Organizing Map algorithm.\n\nWould you like me to:\n1. Add more examples\n2. Expand any section\n3. Add installation or dependency details\n4. Add anything else?\n\n:::\n\n**AI Prompt**\n\nLast request! Can you generate a TOC for the whole notebook that I will prepend for easier navigation?\n\n**AI Response**\n\nHere's a Table of Contents for your notebook:\n\n```markdown\n# Self-Organizing Map Implementation\n\n## Table of Contents\n\nI. CORE SOM COMPONENTS\n   - I.1 Weight Grid Initialization\n   - I.2 Distance Metrics\n   - I.3 BMU (Best Matching Unit)\n   - I.4 Neighborhood Function\n   - I.5 Weight Update Rule\n\nII. EXTENDED TRAINING COMPONENTS\n   - II.1 A 2D Toy Dataset\n   - II.2 U-Matrix\n   - II.3 Naive Training Loop\n   - II.4 Quantization Error (QE)\n   - II.5 Topographic Error (TE)\n   - II.6 LR and σ Schedulers\n   - II.7 Advanced Training Loop with Schedulers\n   - II.8 Revised Plan\n\nIII. WEIGHTS INITIALIZATION METHODS\n   - III.1 Random Initialization\n   - III.2 PCA Initialization\n\nIV. ADDITIONAL VISUALIZATIONS\n\nV. REFACTORING\n   - V.1 Class Implementation\n   - V.2 README.md\n\nEach section follows the step-by-step development process, from basic components to the final package implementation.\nWould you like me to: 1. Add more detail to any section 2. Reorganize any part 3. Add subsections I might have missed?",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#quick-start",
    "href": "workflow/how-was-it-created.html#quick-start",
    "title": "How was it created?",
    "section": "Quick Start",
    "text": "Quick Start\nfrom teuvo import SOM\nimport numpy as np\nfrom sklearn.datasets import load_digits\n\n# Load and normalize MNIST data\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Create and train SOM\nsom = SOM(grid_sz=(20,20), input_dim=64, init='pca')\nsom.fit(X_norm, n_epochs=20)\n\n# Visualize results\nsom.plot_umatrix()",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#features",
    "href": "workflow/how-was-it-created.html#features",
    "title": "How was it created?",
    "section": "Features",
    "text": "Features\n\nMultiple initialization methods:\n\nRandom initialization\nPCA-based initialization (for faster convergence)\n\nFlexible training options:\n\nCustomizable learning rate schedules\nAdjustable neighborhood functions\n\nComprehensive quality metrics:\n\nQuantization Error\nTopographic Error\n\nRich visualization tools:\n\nU-Matrix visualization\nComponent planes (coming soon)",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#detailed-example-mnist-digit-classification",
    "href": "workflow/how-was-it-created.html#detailed-example-mnist-digit-classification",
    "title": "How was it created?",
    "section": "Detailed Example: MNIST Digit Classification",
    "text": "Detailed Example: MNIST Digit Classification\nfrom teuvo import SOM\nfrom teuvo.schedulers import Scheduler\nimport numpy as np\nfrom sklearn.datasets import load_digits\nimport matplotlib.pyplot as plt\n\n# Load and preprocess data\nX, y = load_digits(return_X_y=True)\nX_norm = (X - np.mean(X, axis=-1, keepdims=True))/X.max()\n\n# Initialize SOM\nsom = SOM(\n    grid_sz=(20,20),\n    input_dim=64,\n    init='pca'  # Use PCA initialization\n)\n\n# Create custom schedulers\nlr_scheduler = Scheduler(start_val=1.0, end_val=0.01, \n                       step_size=200, n_samples=len(X), n_epochs=20)\nsigma_scheduler = Scheduler(start_val=10.0, end_val=1.0, \n                          step_size=200, n_samples=len(X), n_epochs=20)\n\n# Train\nweights, qe_errors, te_errors = som.fit(\n    X_norm,\n    n_epochs=20,\n    lr_scheduler=lr_scheduler,\n    sigma_scheduler=sigma_scheduler\n)\n\n# Visualize results\nplt.figure(figsize=(12,4))\n\nplt.subplot(121)\nplt.plot(qe_errors)\nplt.title('Quantization Error')\nplt.xlabel('Epoch')\n\nplt.subplot(122)\nsom.plot_umatrix()\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#contributing",
    "href": "workflow/how-was-it-created.html#contributing",
    "title": "How was it created?",
    "section": "Contributing",
    "text": "Contributing\nWe welcome contributions! Please see our contributing guidelines for details.",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#references",
    "href": "workflow/how-was-it-created.html#references",
    "title": "How was it created?",
    "section": "References",
    "text": "References\n\nKohonen, T. (1982). Self-organized formation of topologically correct feature maps\nKohonen, T. (2013). Essentials of the self-organizing map\nPolya, G. (1945). How to Solve It",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#license",
    "href": "workflow/how-was-it-created.html#license",
    "title": "How was it created?",
    "section": "License",
    "text": "License\nMIT",
    "crumbs": [
      "How was it created?"
    ]
  },
  {
    "objectID": "workflow/how-was-it-created.html#acknowledgments",
    "href": "workflow/how-was-it-created.html#acknowledgments",
    "title": "How was it created?",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nNamed in honor of Teuvo Kohonen, who introduced the Self-Organizing Map algorithm.\n\nWould you like me to:\n1. Add more examples\n2. Expand any section\n3. Add installation or dependency details\n4. Add anything else?\n\n:::\n\n**AI Prompt**\n\nLast request! Can you generate a TOC for the whole notebook that I will prepend for easier navigation?\n\n**AI Response**\n\nHere's a Table of Contents for your notebook:\n\n```markdown\n# Self-Organizing Map Implementation\n\n## Table of Contents\n\nI. CORE SOM COMPONENTS\n   - I.1 Weight Grid Initialization\n   - I.2 Distance Metrics\n   - I.3 BMU (Best Matching Unit)\n   - I.4 Neighborhood Function\n   - I.5 Weight Update Rule\n\nII. EXTENDED TRAINING COMPONENTS\n   - II.1 A 2D Toy Dataset\n   - II.2 U-Matrix\n   - II.3 Naive Training Loop\n   - II.4 Quantization Error (QE)\n   - II.5 Topographic Error (TE)\n   - II.6 LR and σ Schedulers\n   - II.7 Advanced Training Loop with Schedulers\n   - II.8 Revised Plan\n\nIII. WEIGHTS INITIALIZATION METHODS\n   - III.1 Random Initialization\n   - III.2 PCA Initialization\n\nIV. ADDITIONAL VISUALIZATIONS\n\nV. REFACTORING\n   - V.1 Class Implementation\n   - V.2 README.md\n\nEach section follows the step-by-step development process, from basic components to the final package implementation.\nWould you like me to: 1. Add more detail to any section 2. Reorganize any part 3. Add subsections I might have missed?",
    "crumbs": [
      "How was it created?"
    ]
  }
]